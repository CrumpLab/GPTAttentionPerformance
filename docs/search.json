[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "The purpose of this project is to assess capabilities of LLMs, such as OpenAI’s gpt models, to simulate behavioral data from classic attention and performance tasks in cognitive psychology, like the Stroop task.\nStatus:\n\nIn progress\nExploratory"
  },
  {
    "objectID": "index.html#project-information",
    "href": "index.html#project-information",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "The purpose of this project is to assess capabilities of LLMs, such as OpenAI’s gpt models, to simulate behavioral data from classic attention and performance tasks in cognitive psychology, like the Stroop task.\nStatus:\n\nIn progress\nExploratory"
  },
  {
    "objectID": "index.html#repository-information",
    "href": "index.html#repository-information",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "Repository Information",
    "text": "Repository Information\nThis is a website for a cognitive psychology research project. The aim of this website is to create and share reproducible research assets throughout the project lifespan. This repository is built with quarto. Source code is available from the github repository for this project."
  },
  {
    "objectID": "modeling/todo.html",
    "href": "modeling/todo.html",
    "title": "Project Scratchpad",
    "section": "",
    "text": "I’ve already started on the work in a blog post: https://crumplab.com/blog/771_GPT_Stroop/\nNeed to briefly list what I’ve done already.\nThen, come up with some goals for moving the project forward."
  },
  {
    "objectID": "modeling/todo.html#blog-post-summary",
    "href": "modeling/todo.html#blog-post-summary",
    "title": "Project Scratchpad",
    "section": "Blog post summary",
    "text": "Blog post summary\n\nBriefly described the Stroop task\nDevelops some motivation for why I care whether or not LLMs can simulate performance in a Stroop-task\n\ndata-spoofing, such as mturk workers using LLMs to exploit online tasks.\n\nDescribe methods\n\nuse the openai API and R to send instructions for a Stroop task, and then individual trials (in text format)\nhave the model simulate trial-by-trial responses and reaction times, return them in JSON\nanalyse the data and see what happens\n\nThe post shows some draft code to simulate a single subject, and to simulate multiple subjects\nGot data from 10 simulated subjects\nResults showed:\n\ngpt-3.5-turbo generated data files that showed Stroop effects\nSimulated RTs were different across simulated subjects\nAccuracy was 100%\nRTs looked almost credible. Many individual RTs had 0 ending, and were too round looking."
  },
  {
    "objectID": "modeling/todo.html#to-do",
    "href": "modeling/todo.html#to-do",
    "title": "Project Scratchpad",
    "section": "To do",
    "text": "To do\nNot an exhaustive list, something to get me started.\n\nSettle on one script that can be extended across the examples.\nRun multiple subjects, say batches of 20-30, which should be enough for the kinds of questions I want to ask\n\nAnswer the following basic questions\n\nDoes the model produce Stroop effects in RT and accuracy?\nDoes the model produce different answers for each run of simulated subjects?\nDoes the model produce RTs that look like human subject RTs?\nDoes the model produce additional Stroop phenomena without further prompting?\n\nCongruency sequence effect?\n[] Proportion Congruent effect?\n\nCan the instruction prompt be used to control how the model simulates performance.\n\nsimulate 75% correct\n[] simulate 50% correct\n[] simulate some long reaction times\n[] simulate a reverse Stroop effect.\n[] simulate proportion congruent effects"
  },
  {
    "objectID": "modeling/todo.html#simulations",
    "href": "modeling/todo.html#simulations",
    "title": "Project Scratchpad",
    "section": "Simulations",
    "text": "Simulations\n\nSimulation 1: Basic Stroop\n25 simulated subjects. 24 trials each. 50% congruent/incongruent. Simple instruction prompt. Shows Stroop effects, and congruent sequence effects. RTs are too round. Accuracy is too good.\n\n\nSimulation 2: Stroop Instructions\nSame as above, but change to prompt for more “random” RTs, and worse accuracy. This worked.\n\n\nSimulation 3: Proportion congruent\nGive the model a low or high proportion congruent list. Don’t say anything about high or low proportion congruent being an issue in the prompt. See if the model generates data that nevertheless show a proportion congruent effect.\n\n\nSimulation 4: Reverse the task\nHave the model perform “word-reading” instead of “color-naming”. This usually shows a much smaller Stroop. What does the model do?"
  },
  {
    "objectID": "modeling/simulation_2.html",
    "href": "modeling/simulation_2.html",
    "title": "Simulation 2: Stroop instructions",
    "section": "",
    "text": "Simulation 1 showed that several aspects of trial-to-trial performance in a Stroop task can be simulated by gpt-3.5-turbo. However, some aspects of performance were too good to be human. First, the model produced perfect responses on all trials. Second, the simulated reaction time values were too round, and usually ended in zero or five. Simulation 2 determines whether changes to the prompt instructions can deliver different patterns of results. The prompt will include instructions to perform with accuracy rates betweeen 85% to 95%. The prompt will include instructions to generate reaction time results that end in any number."
  },
  {
    "objectID": "modeling/simulation_2.html#goal",
    "href": "modeling/simulation_2.html#goal",
    "title": "Simulation 2: Stroop instructions",
    "section": "",
    "text": "Simulation 1 showed that several aspects of trial-to-trial performance in a Stroop task can be simulated by gpt-3.5-turbo. However, some aspects of performance were too good to be human. First, the model produced perfect responses on all trials. Second, the simulated reaction time values were too round, and usually ended in zero or five. Simulation 2 determines whether changes to the prompt instructions can deliver different patterns of results. The prompt will include instructions to perform with accuracy rates betweeen 85% to 95%. The prompt will include instructions to generate reaction time results that end in any number."
  },
  {
    "objectID": "modeling/simulation_2.html#load-libraries",
    "href": "modeling/simulation_2.html#load-libraries",
    "title": "Simulation 2: Stroop instructions",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/simulation_2.html#run-model",
    "href": "modeling/simulation_2.html#run-model",
    "title": "Simulation 2: Stroop instructions",
    "section": "Run model",
    "text": "Run model\nNotes: 25 simulated subjects. 24 Stroop trials each. 50% congruent/incongruent items made up from combinations of red, green, blue, and yellow. Each subject is given a different randomized order.\nThe new prompt is shown in the code.\nTiming it this time. Started at 3:10. Took about 14 minutes.\nUsed default params for gpt-3.5-turbo from the openai library.\n\n\nShow the code\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- c(\"The word red printed in the color red\",\n                     \"The word blue printed in the color blue\",\n                     \"The word yellow printed in the color yellow\",\n                     \"The word green printed in the color green\")\n\n# four possible incongruent items\nincongruent_items &lt;- c(\"The word red printed in the color blue\",\n                       \"The word red printed in the color green\",\n                       \"The word red printed in the color yellow\",\n                       \"The word blue printed in the color red\",\n                       \"The word blue printed in the color green\",\n                       \"The word blue printed in the color yellow\",\n                       \"The word yellow printed in the color red\",\n                       \"The word yellow printed in the color blue\",\n                       \"The word yellow printed in the color green\",\n                       \"The word green printed in the color red\",\n                       \"The word green printed in the color blue\",\n                       \"The word green printed in the color yellow\")\n\n# generate 50% congruent and 50% incongruent trials\n# 12 each (congruent and incongruent)\ntrials &lt;- sample(c(rep(congruent_items,3),incongruent_items))\n\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:25){\n  print(i)\n  \n  gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo\",\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste(\"Consider the following trials of a Stroop task where you are supposed to identify the ink-color of the word as quickly and accurately as possible.\",\"-----\", paste(1:24, trials, collapse=\"\\n\") , \"-----\",'This is a simulated Stroop task. You will be shown a Stroop item in the form of a sentence. The sentence will describe a word presented in a particular ink-color. Your task is to identify the ink-color of the word as quickly and accurately as a human participant would. Your simulated accuracy should be between 80 and 95 percent accurate. Your simulated reaction times should look like real human data and end in different numbers. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].', sep=\"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"word\",\"color\",\"response\",\"reaction_time\")) == 5) {\n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_2.RData\")"
  },
  {
    "objectID": "modeling/simulation_2.html#analysis",
    "href": "modeling/simulation_2.html#analysis",
    "title": "Simulation 2: Stroop instructions",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_2.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 25 times, but still need to compute the total number of valid simulated subjects.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 25 out of 25 valid simulated subjects.\n\nReaction time analysis\n\n\nShow the code\n# get mean RTs in each condition for each subject\nrt_data_subject_congruency &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n# Compute difference scores for each subject\nrt_data_subject_stroop &lt;- rt_data_subject_congruency %&gt;%\n  pivot_wider(names_from = congruency,\n              values_from = mean_rt) %&gt;%\n  mutate(Stroop_effect = incongruent-congruent)\n\n# make plots\n\nF1A &lt;- ggplot(rt_data_subject_congruency, aes(x = congruency,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  ggtitle(\"A\")\n\nF1B &lt;- ggplot(rt_data_subject_stroop, aes(x = ' ',\n                                   y = Stroop_effect))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Stroop Effects\")+\n  xlab(\"Incongruent - Congruent\")+\n  ggtitle(\"B\")\n\nF1A + F1B\n\n\n\n\n\nFigure 1A shows simulated mean reaction times for congruent and incongruent trials. Individual dots show means at the level of simulated subjects. Figure 1B shows the overall mean Stroop effect, and individual mean Stroop effects for each simulated subject. The results are similar to Simulatoin 1.\n\n\nA closer look at reaction times\nThe new prompt included the instructions: “Your simulated accuracy should be between 80 and 95 percent accurate. Your simulated reaction times should look like real human data and end in different numbers.” A major question for simulation 2 was to determine if this prompt would cause the model to generate less round numbers.\nThe histogram looks more like an ex-Gaussian than simulation 1.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nSetting the bin-wdith smaller shows that the model used many more numbers in between round intervals.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=10, color=\"white\")+\n  scale_x_continuous(breaks=seq(250,1000,50))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe following histogram is a count of the ending digits for each of the simulated reaction times generated by gpt-3.5-turbo. The new prompt was effective in causing the model to propuce numbers with all possible endings.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/simulation_2.html#accuracy-analysis",
    "href": "modeling/simulation_2.html#accuracy-analysis",
    "title": "Simulation 2: Stroop instructions",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\nAnother major question was whether the new prompt would cause less than perfect accuracy on all trials. The model remained 100% accurate on congruent trials, but produced a variety of accuracy rates for incongruent trials.\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(proportion_correct = sum(accuracy)/12, .groups = \"drop\")\n\nggplot(accuracy_data_subject, aes(x = congruency,\n                                  y = proportion_correct))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Proportion Correct\")+\n  xlab(\"Congruency\")\n\n\n\n\n\nThe accuracy rates for incongruent items have a clear stepped, almost equal interval like pattern. The prompt succeeded in producing imperfect accuracy rates, but the model did not comply with the instruction to produce accuracy rates between 80-95 percent correct."
  },
  {
    "objectID": "modeling/simulation_2.html#discussion",
    "href": "modeling/simulation_2.html#discussion",
    "title": "Simulation 2: Stroop instructions",
    "section": "Discussion",
    "text": "Discussion\nThe purpose of simulation 2 was to determine if simple changes to the instruction would influence the simulated results, such as producing more “random” looking reaction times, and more inaccurate responses. The reaction times in simulation 2 looked more “random” and ex-Gaussian than the reaction times in Simulation 1. The accuracy rates remained perfect for congruent items, but not for incongruent items, which showed a wide range of accuracy rates."
  },
  {
    "objectID": "modeling/simulation_1.html",
    "href": "modeling/simulation_1.html",
    "title": "Simulation 1: Basic Stroop",
    "section": "",
    "text": "The goal of simulation 1 is to determine whether or not gpt-3.5-turbo is capable of simulating performance in a standard Stroop task. To accomplish this, the model will be given a text-based Stroop task where it will be shown a word presented in a particular color. On each trial, the model will be instructed to respond as quickly and accurately as possible to identify the color. The response will include the name of the color and a simulated reaction time in milliseconds. To facilitate easy analysis in R, the model is instructed to return results in JSON format."
  },
  {
    "objectID": "modeling/simulation_1.html#goal",
    "href": "modeling/simulation_1.html#goal",
    "title": "Simulation 1: Basic Stroop",
    "section": "",
    "text": "The goal of simulation 1 is to determine whether or not gpt-3.5-turbo is capable of simulating performance in a standard Stroop task. To accomplish this, the model will be given a text-based Stroop task where it will be shown a word presented in a particular color. On each trial, the model will be instructed to respond as quickly and accurately as possible to identify the color. The response will include the name of the color and a simulated reaction time in milliseconds. To facilitate easy analysis in R, the model is instructed to return results in JSON format."
  },
  {
    "objectID": "modeling/simulation_1.html#load-libraries",
    "href": "modeling/simulation_1.html#load-libraries",
    "title": "Simulation 1: Basic Stroop",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/simulation_1.html#run-model",
    "href": "modeling/simulation_1.html#run-model",
    "title": "Simulation 1: Basic Stroop",
    "section": "Run model",
    "text": "Run model\nNotes: 25 simulated subjects. 24 Stroop trials each. 50% congruent/incongruent items made up from combinations of red, green, blue, and yellow. Each subject is given a different randomized order. Instructions are minimal: to identify the color as quickly and accurately as possible.\nTakes about 10 minutes or so run, maybe less, didn’t time it.\nUsed default params for gpt-3.5-turbo from the openai library.\n\n\nShow the code\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- c(\"The word red printed in the color red\",\n                     \"The word blue printed in the color blue\",\n                     \"The word yellow printed in the color yellow\",\n                     \"The word green printed in the color green\")\n\n# four possible incongruent items\nincongruent_items &lt;- c(\"The word red printed in the color blue\",\n                       \"The word red printed in the color green\",\n                       \"The word red printed in the color yellow\",\n                       \"The word blue printed in the color red\",\n                       \"The word blue printed in the color green\",\n                       \"The word blue printed in the color yellow\",\n                       \"The word yellow printed in the color red\",\n                       \"The word yellow printed in the color blue\",\n                       \"The word yellow printed in the color green\",\n                       \"The word green printed in the color red\",\n                       \"The word green printed in the color blue\",\n                       \"The word green printed in the color yellow\")\n\n# generate 50% congruent and 50% incongruent trials\n# 12 each (congruent and incongruent)\ntrials &lt;- sample(c(rep(congruent_items,3),incongruent_items))\n\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:25){\n  print(i)\n  \n  gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo\",\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Your task is to respond as quickly and accurately as possible, and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste(\"Consider the following trials of a Stroop task where you are supposed to identify the ink-color of the word as quickly and accurately as possible.\",\"-----\", paste(1:24, trials, collapse=\"\\n\") , \"-----\",'This is a simulated Stroop task. You will be shown a Stroop item in the form of a sentence. The sentence will describe a word presented in a particular ink-color. Your task is to identify the ink-color of the word as quickly and accurately as possible. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].', sep=\"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"word\",\"color\",\"response\",\"reaction_time\")) == 5) {\n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_1.RData\")"
  },
  {
    "objectID": "modeling/simulation_1.html#analysis",
    "href": "modeling/simulation_1.html#analysis",
    "title": "Simulation 1: Basic Stroop",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_1.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 25 times, but still need to compute the total number of valid simulated subjects.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 23 out of 25 valid simulated subjects.\n\nReaction time analysis\n\n\nShow the code\n# get mean RTs in each condition for each subject\nrt_data_subject_congruency &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n# Compute difference scores for each subject\nrt_data_subject_stroop &lt;- rt_data_subject_congruency %&gt;%\n  pivot_wider(names_from = congruency,\n              values_from = mean_rt) %&gt;%\n  mutate(Stroop_effect = incongruent-congruent)\n\n# make plots\n\nF1A &lt;- ggplot(rt_data_subject_congruency, aes(x = congruency,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  ggtitle(\"A\")\n\nF1B &lt;- ggplot(rt_data_subject_stroop, aes(x = ' ',\n                                   y = Stroop_effect))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Stroop Effects\")+\n  xlab(\"Incongruent - Congruent\")+\n  ggtitle(\"B\")\n\nF1A + F1B\n\n\n\n\n\nFigure 1A shows simulated mean reaction times for congruent and incongruent trials. Individual dots show means at the level of simulated subjects. Figure 1B shows the overall mean Stroop effect, and individual mean Stroop effects for each simulated subject. 22 of the 23 simulated subjects showed positive Stroop effects, and one simulated subject showed a reverse Stroop effect.\nThe major take home point is that the LLM is capable of generating data that have grossly similar characteristics to human reaction time data in the Stroop task. First, the model produces faster responses to congruent than incongruent trials. Second, the model generates data patterns stochastically, and individual simulated subjects showed different patterns of reaction time data. The range of reaction time values is not outside the range found in studies with human participants.\n\n\nA closer look at reaction times\nHuman reaction time data is often distributed like a normal distribution with a long tail, also termed an ex-Gaussian distribution. Combining across all of the simulated subjects, what does the histogram of simulated RTs look like? At a group level, the reactions time look almost plausible.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe next histogram changes the binwidth. The simulated RTs are not spaced equally within the distribution. Many of the numbers are too “round”, like 400, 450, 500, etc.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=10, color=\"white\")+\n  scale_x_continuous(breaks=seq(250,1000,50))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe following histogram is a count of the ending digits for each of the simulated reaction times generated by gpt-3.5-turbo. A large majority of the values ended in zero, with five scoring a distance second. One question for future simulations is whether this behavior can be modified by changing the prompt to the model.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/simulation_1.html#accuracy-analysis",
    "href": "modeling/simulation_1.html#accuracy-analysis",
    "title": "Simulation 1: Basic Stroop",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(proportion_correct = sum(accuracy)/12, .groups = \"drop\") %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = congruency,\n              values_from = proportion_correct) %&gt;%\n  mutate(Stroop_effect = incongruent-congruent)\n\n\nEvery simulated subject scored 100% accurate on both congruent and incongruent trials."
  },
  {
    "objectID": "modeling/simulation_1.html#congruency-sequence-effect",
    "href": "modeling/simulation_1.html#congruency-sequence-effect",
    "title": "Simulation 1: Basic Stroop",
    "section": "Congruency Sequence effect",
    "text": "Congruency Sequence effect\nA common finding in the Stroop literature is that Stroop effects are larger following congruent trials than incongruent trials. This information was not included in the prompt. The purpose of this analysis is to determine whether the LLM generates simulated RT data that also contain congruency sequence effects.\n\n\nShow the code\n# add last trial congruency as a factor\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\"))\n\nall_sim_data$last_trial_congruent &lt;- c(NA,all_sim_data$congruency[1:(dim(all_sim_data)[1]-1)])\n\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(last_trial_congruent = case_when(trial == 1 ~ NA,\n                                          trial != 1 ~ last_trial_congruent)) \n\n# report rt data\nrt_data_subject_seq &lt;- all_sim_data %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE,\n         is.na(last_trial_congruent) == FALSE) %&gt;%\n  mutate(last_trial_congruent = paste0(\"n1\",last_trial_congruent)) %&gt;%\n  group_by(congruency,last_trial_congruent,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\") %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = c(congruency,last_trial_congruent),\n              values_from = mean_rt) %&gt;%\n  mutate(Previous_congruent = incongruent_n1congruent-congruent_n1congruent,\n         Previous_incongruent = incongruent_n1incongruent-congruent_n1incongruent\n         ) %&gt;%\n  pivot_longer(cols = c(\"Previous_congruent\",\"Previous_incongruent\"),\n               names_to = \"Sequential\") %&gt;%\n  mutate(Sequential = as.factor(Sequential)) %&gt;%\n  mutate(Sequential = recode(Sequential,\n                             \"Previous_congruent\" = \"N-1 Congruent\",\n                             \"Previous_incongruent\" = \"N-1 Incongruent\"\n                             ))\n\n# make plots\n\nggplot(rt_data_subject_seq, aes(x = Sequential,\n                                y = value))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Stroop Effect\") +\n  xlab(\"Previous Trial\")\n\n\n\n\n\n\n\nShow the code\n# ANOVA\n\n# ensure factors\nrt_data_subject_seq &lt;- rt_data_subject_seq %&gt;%\n  mutate(sim_subject = factor(sim_subject))\n\n# run ANOVA\naov_sequential &lt;- aov(value ~ Sequential + Error(sim_subject/Sequential), data = rt_data_subject_seq)\n\n# save printable summaries\napa_print &lt;- papaja::apa_print(aov_sequential)\n\nknitr::kable(xtable(summary(aov_sequential)))\n\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nResiduals\n22\n390332.87\n17742.403\nNA\nNA\n\n\nSequential\n1\n46160.66\n46160.657\n20.52313\n0.0001652\n\n\nResiduals\n22\n49482.43\n2249.201\nNA\nNA\n\n\n\n\n\nAuthor’s note: Huh.\nIn this simulation of 23 subjects, the mean Stroop effect was larger for trials preceded by a congruent item compared to trials preceded by an incongruent item, \\(F(1, 22) = 20.52\\), \\(p &lt; .001\\), \\(\\hat{\\eta}^2_G = .095\\), 90% CI \\([.000, .316]\\)."
  },
  {
    "objectID": "modeling/simulation_1.html#discussion",
    "href": "modeling/simulation_1.html#discussion",
    "title": "Simulation 1: Basic Stroop",
    "section": "Discussion",
    "text": "Discussion\nGpt-3.5-turbo produced simulated data that approximated human behavior in several respects, including producing standard Stroop effects, and even a congruency sequence effect. The accuracy data was too perfect, and the reaction time data was too round (most numbers ended in zeros.)\nGeneral caveats. This code can be re-run, but the result is not completely reproducible because the LLM is stochastic and will return different answers each time."
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "The purpose of this project is to assess capabilities of LLMs, such as OpenAI’s gpt models, to simulate behavioral data from classic attention and performance tasks in cognitive psychology, like the Stroop task.\nStatus:\n\nIn progress\nExploratory\n\n\n\n\nThis is a website for a cognitive psychology research project. The aim of this website is to create and share reproducible research assets throughout the project lifespan. This repository is built with quarto. Source code is available from the github repository for this project."
  },
  {
    "objectID": "readme.html#project-information",
    "href": "readme.html#project-information",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "The purpose of this project is to assess capabilities of LLMs, such as OpenAI’s gpt models, to simulate behavioral data from classic attention and performance tasks in cognitive psychology, like the Stroop task.\nStatus:\n\nIn progress\nExploratory"
  },
  {
    "objectID": "readme.html#repository-information",
    "href": "readme.html#repository-information",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "This is a website for a cognitive psychology research project. The aim of this website is to create and share reproducible research assets throughout the project lifespan. This repository is built with quarto. Source code is available from the github repository for this project."
  }
]