[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "The purpose of this project is to assess capabilities of LLMs, such as OpenAI’s GPT models, to simulate behavioral data from classic attention and performance tasks in cognitive psychology, like the Stroop task.\nStatus:\n\nIn progress\nExploratory"
  },
  {
    "objectID": "index.html#project-information",
    "href": "index.html#project-information",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "The purpose of this project is to assess capabilities of LLMs, such as OpenAI’s GPT models, to simulate behavioral data from classic attention and performance tasks in cognitive psychology, like the Stroop task.\nStatus:\n\nIn progress\nExploratory"
  },
  {
    "objectID": "index.html#repository-information",
    "href": "index.html#repository-information",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "Repository Information",
    "text": "Repository Information\nThis is a website for a cognitive psychology research project. The aim of this website is to create and share reproducible research assets throughout the project lifespan. This repository is built with quarto. Source code is available from the github repository for this project."
  },
  {
    "objectID": "modeling/S1_basic_stroop.html",
    "href": "modeling/S1_basic_stroop.html",
    "title": "Simulation 1: Basic Stroop",
    "section": "",
    "text": "The goal of simulation 1 is to determine whether or not GPT-3.5-turbo is capable of simulating performance in a standard Stroop task. To accomplish this, the model will be given a text-based Stroop task where it will be shown a word presented in a particular color. On each trial, the model will be instructed to respond as quickly and accurately as possible to identify the color. The response will include the name of the color and a simulated reaction time in milliseconds. To facilitate easy analysis in R, the model is instructed to return results in JSON format."
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#goal",
    "href": "modeling/S1_basic_stroop.html#goal",
    "title": "Simulation 1: Basic Stroop",
    "section": "",
    "text": "The goal of simulation 1 is to determine whether or not GPT-3.5-turbo is capable of simulating performance in a standard Stroop task. To accomplish this, the model will be given a text-based Stroop task where it will be shown a word presented in a particular color. On each trial, the model will be instructed to respond as quickly and accurately as possible to identify the color. The response will include the name of the color and a simulated reaction time in milliseconds. To facilitate easy analysis in R, the model is instructed to return results in JSON format."
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#load-libraries",
    "href": "modeling/S1_basic_stroop.html#load-libraries",
    "title": "Simulation 1: Basic Stroop",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#run-model",
    "href": "modeling/S1_basic_stroop.html#run-model",
    "title": "Simulation 1: Basic Stroop",
    "section": "Run model",
    "text": "Run model\nNotes: 25 simulated subjects. 24 Stroop trials each. 50% congruent/incongruent items made up from combinations of red, green, blue, and yellow. Instructions are minimal: to identify the color as quickly and accurately as possible.\nAdditional note: I had the original intention to randomize the trial list for each simulated subject. However, the code below randomized the list once, and gave all simulated subjects the same list.\nTakes about 10 minutes or so run, maybe less, didn’t time it.\nUsed default params for gpt-3.5-turbo from the openai library.\n\n\nShow the code\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- c(\"The word red printed in the color red\",\n                     \"The word blue printed in the color blue\",\n                     \"The word yellow printed in the color yellow\",\n                     \"The word green printed in the color green\")\n\n# four possible incongruent items\nincongruent_items &lt;- c(\"The word red printed in the color blue\",\n                       \"The word red printed in the color green\",\n                       \"The word red printed in the color yellow\",\n                       \"The word blue printed in the color red\",\n                       \"The word blue printed in the color green\",\n                       \"The word blue printed in the color yellow\",\n                       \"The word yellow printed in the color red\",\n                       \"The word yellow printed in the color blue\",\n                       \"The word yellow printed in the color green\",\n                       \"The word green printed in the color red\",\n                       \"The word green printed in the color blue\",\n                       \"The word green printed in the color yellow\")\n\n# generate 50% congruent and 50% incongruent trials\n# 12 each (congruent and incongruent)\ntrials &lt;- sample(c(rep(congruent_items,3),incongruent_items))\n\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:25){\n  print(i)\n  \n  gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo\",\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Your task is to respond as quickly and accurately as possible, and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste(\"Consider the following trials of a Stroop task where you are supposed to identify the ink-color of the word as quickly and accurately as possible.\",\"-----\", paste(1:24, trials, collapse=\"\\n\") , \"-----\",'This is a simulated Stroop task. You will be shown a Stroop item in the form of a sentence. The sentence will describe a word presented in a particular ink-color. Your task is to identify the ink-color of the word as quickly and accurately as possible. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].', sep=\"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"word\",\"color\",\"response\",\"reaction_time\")) == 5) {\n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_1.RData\")"
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#analysis",
    "href": "modeling/S1_basic_stroop.html#analysis",
    "title": "Simulation 1: Basic Stroop",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_1.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 25 times, but still need to compute the total number of valid simulated subjects.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 23 out of 25 valid simulated subjects.\n\nReaction time analysis\n\n\nShow the code\n# get mean RTs in each condition for each subject\nrt_data_subject_congruency &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n# Compute difference scores for each subject\nrt_data_subject_stroop &lt;- rt_data_subject_congruency %&gt;%\n  pivot_wider(names_from = congruency,\n              values_from = mean_rt) %&gt;%\n  mutate(Stroop_effect = incongruent-congruent)\n\n# make plots\n\nF1A &lt;- ggplot(rt_data_subject_congruency, aes(x = congruency,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  ggtitle(\"A\")\n\nF1B &lt;- ggplot(rt_data_subject_stroop, aes(x = ' ',\n                                   y = Stroop_effect))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Stroop Effects\")+\n  xlab(\"Incongruent - Congruent\")+\n  ggtitle(\"B\")\n\nF1A + F1B\n\n\n\n\n\nFigure 1A shows simulated mean reaction times for congruent and incongruent trials. Individual dots show means at the level of simulated subjects. Figure 1B shows the overall mean Stroop effect and individual mean Stroop effects for each simulated subject. 22 of the 23 simulated subjects showed positive Stroop effects, and one simulated subject showed a reverse Stroop effect.\nThe major take home point is that the LLM is capable of generating data that have grossly similar characteristics to human reaction time data in the Stroop task. First, the model produces faster responses to congruent than incongruent trials. Second, the model generates data patterns stochastically, and individual simulated subjects showed different patterns of reaction time data. The range of reaction time values is not outside the range found in studies with human participants.\n\n\nA closer look at reaction times\nHuman reaction time data is often distributed like a normal distribution with a long tail, also termed an ex-Gaussian distribution. Combining across all of the simulated subjects, what does the histogram of simulated RTs look like? At a group level, the reactions time look almost plausible.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe next histogram changes the binwidth. The simulated RTs are not spaced equally within the distribution. Many of the numbers are too “round”, like 400, 450, 500, etc.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=10, color=\"white\")+\n  scale_x_continuous(breaks=seq(250,1000,50))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe following histogram is a count of the ending digits for each of the simulated reaction times generated by gpt-3.5-turbo. A large majority of the values ended in zero, with five scoring a distance second. One question for future simulations is whether this behavior can be modified by changing the prompt to the model.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#accuracy-analysis",
    "href": "modeling/S1_basic_stroop.html#accuracy-analysis",
    "title": "Simulation 1: Basic Stroop",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(proportion_correct = sum(accuracy)/12, .groups = \"drop\") %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = congruency,\n              values_from = proportion_correct) %&gt;%\n  mutate(Stroop_effect = incongruent-congruent)\n\n\nEvery simulated subject scored 100% accurate on both congruent and incongruent trials."
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#congruency-sequence-effect",
    "href": "modeling/S1_basic_stroop.html#congruency-sequence-effect",
    "title": "Simulation 1: Basic Stroop",
    "section": "Congruency Sequence effect",
    "text": "Congruency Sequence effect\nA common finding in the Stroop literature is that Stroop effects are larger following congruent trials than incongruent trials. This information was not included in the prompt. The purpose of this analysis is to determine whether the LLM generates simulated RT data that also contain congruency sequence effects.\n\n\nShow the code\n# add last trial congruency as a factor\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\"))\n\nall_sim_data$last_trial_congruent &lt;- c(NA,all_sim_data$congruency[1:(dim(all_sim_data)[1]-1)])\n\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(last_trial_congruent = case_when(trial == 1 ~ NA,\n                                          trial != 1 ~ last_trial_congruent)) \n\n# report rt data\nrt_data_subject_seq &lt;- all_sim_data %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE,\n         is.na(last_trial_congruent) == FALSE) %&gt;%\n  mutate(last_trial_congruent = paste0(\"n1\",last_trial_congruent)) %&gt;%\n  group_by(congruency,last_trial_congruent,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\") %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = c(congruency,last_trial_congruent),\n              values_from = mean_rt) %&gt;%\n  mutate(Previous_congruent = incongruent_n1congruent-congruent_n1congruent,\n         Previous_incongruent = incongruent_n1incongruent-congruent_n1incongruent\n         ) %&gt;%\n  pivot_longer(cols = c(\"Previous_congruent\",\"Previous_incongruent\"),\n               names_to = \"Sequential\") %&gt;%\n  mutate(Sequential = as.factor(Sequential)) %&gt;%\n  mutate(Sequential = recode(Sequential,\n                             \"Previous_congruent\" = \"N-1 Congruent\",\n                             \"Previous_incongruent\" = \"N-1 Incongruent\"\n                             ))\n\n# make plots\n\nggplot(rt_data_subject_seq, aes(x = Sequential,\n                                y = value))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Stroop Effect\") +\n  xlab(\"Previous Trial\")\n\n\n\n\n\n\n\nShow the code\n# ANOVA\n\n# ensure factors\nrt_data_subject_seq &lt;- rt_data_subject_seq %&gt;%\n  mutate(sim_subject = factor(sim_subject))\n\n# run ANOVA\naov_sequential &lt;- aov(value ~ Sequential + Error(sim_subject/Sequential), data = rt_data_subject_seq)\n\n# save printable summaries\napa_print &lt;- papaja::apa_print(aov_sequential)\n\nknitr::kable(xtable(summary(aov_sequential)))\n\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nResiduals\n22\n390332.87\n17742.403\nNA\nNA\n\n\nSequential\n1\n46160.66\n46160.657\n20.52313\n0.0001652\n\n\nResiduals\n22\n49482.43\n2249.201\nNA\nNA\n\n\n\n\n\nAuthor’s note: Huh.\nIn this simulation of 23 subjects, the mean Stroop effect was larger for trials preceded by a congruent item compared to trials preceded by an incongruent item, \\(F(1, 22) = 20.52\\), \\(p &lt; .001\\), \\(\\hat{\\eta}^2_G = .095\\), 90% CI \\([.000, .316]\\)."
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#discussion",
    "href": "modeling/S1_basic_stroop.html#discussion",
    "title": "Simulation 1: Basic Stroop",
    "section": "Discussion",
    "text": "Discussion\nGPT-3.5-turbo produced simulated data that approximated human behavior in several respects, including producing standard Stroop effects, and even a congruency sequence effect. The accuracy data was too perfect, and the reaction time data was too round (most numbers ended in zeros.)\nGeneral caveats. This code can be re-run, but the result is not completely reproducible because the LLM is stochastic and will return different answers each time."
  },
  {
    "objectID": "modeling/todo.html",
    "href": "modeling/todo.html",
    "title": "Project Scratchpad",
    "section": "",
    "text": "I’ve already started on the work in a blog post: https://crumplab.com/blog/771_GPT_Stroop/\nNeed to briefly list what I’ve done already.\nThen, come up with some goals for moving the project forward."
  },
  {
    "objectID": "modeling/todo.html#blog-post-summary",
    "href": "modeling/todo.html#blog-post-summary",
    "title": "Project Scratchpad",
    "section": "Blog post summary",
    "text": "Blog post summary\n\nBriefly described the Stroop task\nDevelops some motivation for why I care whether or not LLMs can simulate performance in a Stroop-task\n\ndata-spoofing, such as mturk workers using LLMs to exploit online tasks.\n\nDescribe methods\n\nuse the openai API and R to send instructions for a Stroop task, and then individual trials (in text format)\nhave the model simulate trial-by-trial responses and reaction times, return them in JSON\nanalyse the data and see what happens\n\nThe post shows some draft code to simulate a single subject, and to simulate multiple subjects\nGot data from 10 simulated subjects\nResults showed:\n\ngpt-3.5-turbo generated data files that showed Stroop effects\nSimulated RTs were different across simulated subjects\nAccuracy was 100%\nRTs looked almost credible. Many individual RTs had 0 ending, and were too round looking."
  },
  {
    "objectID": "modeling/todo.html#to-do",
    "href": "modeling/todo.html#to-do",
    "title": "Project Scratchpad",
    "section": "To do",
    "text": "To do\nNot an exhaustive list, something to get me started.\n\nSettle on one script that can be extended across the examples.\nRun multiple subjects, say batches of 20-30, which should be enough for the kinds of questions I want to ask\n\nAnswer the following basic questions\n\nDoes the model produce Stroop effects in RT and accuracy?\nDoes the model produce different answers for each run of simulated subjects?\nDoes the model produce RTs that look like human subject RTs?\nDoes the model produce additional Stroop phenomena without further prompting?\n\nCongruency sequence effect?\n[] Proportion Congruent effect?\n\nCan the instruction prompt be used to control how the model simulates performance.\n\nsimulate 75% correct\n[] simulate 50% correct\n[] simulate some long reaction times\n[] simulate a reverse Stroop effect.\n[] simulate proportion congruent effects"
  },
  {
    "objectID": "modeling/todo.html#simulations",
    "href": "modeling/todo.html#simulations",
    "title": "Project Scratchpad",
    "section": "Simulations",
    "text": "Simulations\n\nSimulation 1: Basic Stroop\n25 simulated subjects. 24 trials each. 50% congruent/incongruent. Simple instruction prompt. Shows Stroop effects, and congruent sequence effects. RTs are too round. Accuracy is too good.\n\n\nSimulation 2: Stroop Instructions\nSame as above, but change to prompt for more “random” RTs, and worse accuracy. This worked.\n\n\nSimulation 3: Proportion congruent\nGive the model a low or high proportion congruent list. Don’t say anything about high or low proportion congruent being an issue in the prompt. See if the model generates data that nevertheless show a proportion congruent effect.\n\n\nSimulation 4: Reverse the task\nHave the model perform “word-reading” instead of “color-naming”. This usually shows a much smaller Stroop. What does the model do?"
  },
  {
    "objectID": "modeling/S3_stroop_pc.html",
    "href": "modeling/S3_stroop_pc.html",
    "title": "Simulation 3: Proportion congruent",
    "section": "",
    "text": "Started Pilot data\nHalf-baked. Successfully ran 14 simulated subjects, but requested 20. May need to refactor the code to allow for longer prompts"
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#state",
    "href": "modeling/S3_stroop_pc.html#state",
    "title": "Simulation 3: Proportion congruent",
    "section": "",
    "text": "Started Pilot data\nHalf-baked. Successfully ran 14 simulated subjects, but requested 20. May need to refactor the code to allow for longer prompts"
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#recap",
    "href": "modeling/S3_stroop_pc.html#recap",
    "title": "Simulation 3: Proportion congruent",
    "section": "Recap",
    "text": "Recap\nSimulation one showed that GPT-3.5-Turbo can complete a Stroop task presented in the form of text prompts, and generate patterns of data that resemble human performance in several respects. For example, the model generated faster reaction times for congruent than incongruent items. The model generated reactions with inter and intra-subject variability. The model also performed with 100% accuracy, and chose implausibly round numbers. The second simulation varied the prompt to encourage more variability in accuracy and reaction time number generation. The reaction times appeared as if they were sampled from a continuous distribution. Accuracy rates for incongruent items varied across subjects.\nIn simulation 1 the model also generated reaction times that were consistent with congruency sequence effects. Specifically, the simulated Stroop effect from trials preceded by a congruent item was found to be larger than the Stroop effect from trials preceded by an incongruent item. The model was not given instructions regarding the congruency sequence, and it is somewhat intriguing that it generated data consistent with the presence of that effect. One possibility is that the models training corpus contains raw data from Stroop experiments, in which case it may be possible that the model generating data patterns for the present simulations in the style of existing training data.\nI don’t know enough about how the model works, or the data it was trained on, to make strong claims or conclusions about these issues. Nevertheless, these issues are relevant to fleshing out concerns about using LLMs to spoof human data. In this case, the model appears to spoof multiple aspects of human performance in the Stroop task.\nThe purpose of the simulation 3 was to determine whether the model will generate data consistent with list-wide proportion congruent effects, without being prompted to do so."
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#load-libraries",
    "href": "modeling/S3_stroop_pc.html#load-libraries",
    "title": "Simulation 3: Proportion congruent",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#run-model",
    "href": "modeling/S3_stroop_pc.html#run-model",
    "title": "Simulation 3: Proportion congruent",
    "section": "Run model",
    "text": "Run model\nNotes: 20 simulated subjects. 32 Stroop trials each. First 10 subjects are given high proportion congruent, last 10 given low proportion congruent.\nUnlike the previous simulations, each subject is given a different randomized order.\nThe new prompt is shown in the code.\nUsed default params for gpt-3.5-turbo from the openai library.\nProblems: This code produced 14 valid JSON files out of 20.\n\n\nShow the code\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- c(\"The word red printed in the color red\",\n                     \"The word blue printed in the color blue\",\n                     \"The word yellow printed in the color yellow\",\n                     \"The word green printed in the color green\")\n\n# four possible incongruent items\nincongruent_items &lt;- c(\"The word red printed in the color blue\",\n                       \"The word red printed in the color green\",\n                       \"The word red printed in the color yellow\",\n                       \"The word blue printed in the color red\",\n                       \"The word blue printed in the color green\",\n                       \"The word blue printed in the color yellow\",\n                       \"The word yellow printed in the color red\",\n                       \"The word yellow printed in the color blue\",\n                       \"The word yellow printed in the color green\",\n                       \"The word green printed in the color red\",\n                       \"The word green printed in the color blue\",\n                       \"The word green printed in the color yellow\")\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:20){\n  print(i)\n  \n  # generate 50% congruent and 50% incongruent trials\n  # 12 each (congruent and incongruent)\n  hpc_trials &lt;-  sample(c(rep(congruent_items,3*2),sample(incongruent_items,8)))\n  lpc_trials &lt;-  sample(c(rep(congruent_items,2),rep(incongruent_items,2)))\n  \n  # choose proportion congruent based on subject number\n  if (i &lt;= 10) {\n    trials &lt;- hpc_trials\n    proportion_congruent &lt;- \"high\"\n  } else {\n    trials &lt;- lpc_trials\n    proportion_congruent &lt;- \"low\"\n  }\n  \n  gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo\",\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste(\"Consider the following trials of a Stroop task where you are supposed to identify the ink-color of the word as quickly and accurately as possible.\",\"-----\", paste(1:32, trials, collapse=\"\\n\") , \"-----\",'This is a simulated Stroop task. You will be shown a Stroop item in the form of a sentence. The sentence will describe a word presented in a particular ink-color. Your task is to identify the ink-color of the word as quickly and accurately as a human participant would. Your simulated reaction times should look like real human data and end in different numbers. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].', sep=\"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"word\",\"color\",\"response\",\"reaction_time\")) == 5) {\n      \n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i,\n               proportion_congruent = proportion_congruent)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_3.RData\")"
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#analysis",
    "href": "modeling/S3_stroop_pc.html#analysis",
    "title": "Simulation 3: Proportion congruent",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_3.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 20 times.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 14 out of 20 valid simulated subjects.\n\nReaction time analysis\nThis analysis has too few simulated subjects to be meaningful.\n\n\nShow the code\n# get mean RTs in each condition for each subject\nrt_data_subject_congruency &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(proportion_congruent,congruency,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n# make plots\n\nggplot(rt_data_subject_congruency, aes(x = congruency,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  facet_wrap(~proportion_congruent)\n\n\n\n\n\n\n\nA closer look at reaction times\nAs with previous simulations, the reaction times look sort of Ex-Gaussian.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nSetting the bin-wdith smaller shows that the model used many more numbers in between round intervals.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=10, color=\"white\")+\n  scale_x_continuous(breaks=seq(250,1000,50))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe model did produce simulated reaction times that ended in all possible digits. At the same time, it shows a preference for values ending in zero.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#accuracy-analysis",
    "href": "modeling/S3_stroop_pc.html#accuracy-analysis",
    "title": "Simulation 3: Proportion congruent",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(proportion_correct = mean(accuracy), .groups = \"drop\")\n\nggplot(accuracy_data_subject, aes(x = congruency,\n                                  y = proportion_correct))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Proportion Correct\")+\n  xlab(\"Congruency\")"
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#discussion",
    "href": "modeling/S3_stroop_pc.html#discussion",
    "title": "Simulation 3: Proportion congruent",
    "section": "Discussion",
    "text": "Discussion\nThis simulation used a slightly longer prompt than the first two simulation. The first two simulations had 24 simulated trials, and this one had 32. I also tried a version with 48 trials per subject, but received 502 gateway errors from the API. I’m not sure whether the prompt was too long, or the expected response was too long."
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html",
    "href": "modeling/S2_stroop_instructions.html",
    "title": "Simulation 2: Stroop instructions",
    "section": "",
    "text": "Simulation 1 showed that several aspects of trial-to-trial performance in a Stroop task can be simulated by gpt-3.5-turbo. However, some aspects of performance were too good to be human. First, the model produced perfect responses on all trials. Second, the simulated reaction time values were too round, and usually ended in zero or five. Simulation 2 determines whether changes to the prompt instructions can deliver different patterns of results. The prompt will include instructions to perform with accuracy rates between 85% and 95%. The prompt will also include instructions to generate reaction time results that end in any number."
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html#goal",
    "href": "modeling/S2_stroop_instructions.html#goal",
    "title": "Simulation 2: Stroop instructions",
    "section": "",
    "text": "Simulation 1 showed that several aspects of trial-to-trial performance in a Stroop task can be simulated by gpt-3.5-turbo. However, some aspects of performance were too good to be human. First, the model produced perfect responses on all trials. Second, the simulated reaction time values were too round, and usually ended in zero or five. Simulation 2 determines whether changes to the prompt instructions can deliver different patterns of results. The prompt will include instructions to perform with accuracy rates between 85% and 95%. The prompt will also include instructions to generate reaction time results that end in any number."
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html#load-libraries",
    "href": "modeling/S2_stroop_instructions.html#load-libraries",
    "title": "Simulation 2: Stroop instructions",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html#run-model",
    "href": "modeling/S2_stroop_instructions.html#run-model",
    "title": "Simulation 2: Stroop instructions",
    "section": "Run model",
    "text": "Run model\nNotes: 25 simulated subjects. 24 Stroop trials each. 50% congruent/incongruent items made up from combinations of red, green, blue, and yellow.\nThe new prompt is shown in the code.\nTiming it this time. Started at 3:10. Took about 14 minutes.\nUsed default params for gpt-3.5-turbo from the openai library.\n\n\nShow the code\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- c(\"The word red printed in the color red\",\n                     \"The word blue printed in the color blue\",\n                     \"The word yellow printed in the color yellow\",\n                     \"The word green printed in the color green\")\n\n# four possible incongruent items\nincongruent_items &lt;- c(\"The word red printed in the color blue\",\n                       \"The word red printed in the color green\",\n                       \"The word red printed in the color yellow\",\n                       \"The word blue printed in the color red\",\n                       \"The word blue printed in the color green\",\n                       \"The word blue printed in the color yellow\",\n                       \"The word yellow printed in the color red\",\n                       \"The word yellow printed in the color blue\",\n                       \"The word yellow printed in the color green\",\n                       \"The word green printed in the color red\",\n                       \"The word green printed in the color blue\",\n                       \"The word green printed in the color yellow\")\n\n# generate 50% congruent and 50% incongruent trials\n# 12 each (congruent and incongruent)\ntrials &lt;- sample(c(rep(congruent_items,3),incongruent_items))\n\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:25){\n  print(i)\n  \n  gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo\",\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste(\"Consider the following trials of a Stroop task where you are supposed to identify the ink-color of the word as quickly and accurately as possible.\",\"-----\", paste(1:24, trials, collapse=\"\\n\") , \"-----\",'This is a simulated Stroop task. You will be shown a Stroop item in the form of a sentence. The sentence will describe a word presented in a particular ink-color. Your task is to identify the ink-color of the word as quickly and accurately as a human participant would. Your simulated accuracy should be between 80 and 95 percent accurate. Your simulated reaction times should look like real human data and end in different numbers. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].', sep=\"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"word\",\"color\",\"response\",\"reaction_time\")) == 5) {\n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_2.RData\")"
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html#analysis",
    "href": "modeling/S2_stroop_instructions.html#analysis",
    "title": "Simulation 2: Stroop instructions",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_2.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 25 times, but still need to compute the total number of valid simulated subjects.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 25 out of 25 valid simulated subjects.\n\nReaction time analysis\n\n\nShow the code\n# get mean RTs in each condition for each subject\nrt_data_subject_congruency &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n# Compute difference scores for each subject\nrt_data_subject_stroop &lt;- rt_data_subject_congruency %&gt;%\n  pivot_wider(names_from = congruency,\n              values_from = mean_rt) %&gt;%\n  mutate(Stroop_effect = incongruent-congruent)\n\n# make plots\n\nF1A &lt;- ggplot(rt_data_subject_congruency, aes(x = congruency,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  ggtitle(\"A\")\n\nF1B &lt;- ggplot(rt_data_subject_stroop, aes(x = ' ',\n                                   y = Stroop_effect))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Stroop Effects\")+\n  xlab(\"Incongruent - Congruent\")+\n  ggtitle(\"B\")\n\nF1A + F1B\n\n\n\n\n\nFigure 1A shows simulated mean reaction times for congruent and incongruent trials. Individual dots show means at the level of simulated subjects. Figure 1B shows the overall mean Stroop effect and individual mean Stroop effects for each simulated subject. The results are similar to Simulation 1.\n\n\nA closer look at reaction times\nThe new prompt included the instructions: “Your simulated accuracy should be between 80 and 95 percent accurate. Your simulated reaction times should look like real human data and end in different numbers.” A major question for simulation 2 was to determine if this prompt would cause the model to generate less round numbers.\nThe histogram looks more like an ex-Gaussian than simulation 1.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nSetting the bin-width smaller shows that the model used many more numbers in between round intervals.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=10, color=\"white\")+\n  scale_x_continuous(breaks=seq(250,1000,50))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe following histogram is a count of the ending digits for each of the simulated reaction times generated by gpt-3.5-turbo. The new prompt was effective in causing the model to produce numbers with all possible endings.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html#accuracy-analysis",
    "href": "modeling/S2_stroop_instructions.html#accuracy-analysis",
    "title": "Simulation 2: Stroop instructions",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\nAnother major question was whether the new prompt would cause less than perfect accuracy on all trials. The model remained 100% accurate on congruent trials, but produced a variety of accuracy rates for incongruent trials.\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(proportion_correct = sum(accuracy)/12, .groups = \"drop\")\n\nggplot(accuracy_data_subject, aes(x = congruency,\n                                  y = proportion_correct))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Proportion Correct\")+\n  xlab(\"Congruency\")\n\n\n\n\n\nThe accuracy rates for incongruent items have a clear stepped, almost equal interval like pattern. The prompt succeeded in producing imperfect accuracy rates, but the model did not comply with the instruction to produce accuracy rates between 80-95 percent correct."
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html#discussion",
    "href": "modeling/S2_stroop_instructions.html#discussion",
    "title": "Simulation 2: Stroop instructions",
    "section": "Discussion",
    "text": "Discussion\nThe purpose of Simulation 2 was to determine if simple changes to the instructions would influence the simulated results. The goal was to produce reaction times that appeared more random and ex-Gaussian, as well as more inaccurate responses. In Simulation 2, the reaction times were indeed more random and ex-Gaussian compared to Simulation 1. While the accuracy rates for congruent items remained perfect, there was a wide range of accuracy rates for incongruent items."
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "The purpose of this project is to assess capabilities of LLMs, such as OpenAI’s gpt models, to simulate behavioral data from classic attention and performance tasks in cognitive psychology, like the Stroop task.\nStatus:\n\nIn progress\nExploratory\n\n\n\n\nThis is a website for a cognitive psychology research project. The aim of this website is to create and share reproducible research assets throughout the project lifespan. This repository is built with quarto. Source code is available from the github repository for this project."
  },
  {
    "objectID": "readme.html#project-information",
    "href": "readme.html#project-information",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "The purpose of this project is to assess capabilities of LLMs, such as OpenAI’s gpt models, to simulate behavioral data from classic attention and performance tasks in cognitive psychology, like the Stroop task.\nStatus:\n\nIn progress\nExploratory"
  },
  {
    "objectID": "readme.html#repository-information",
    "href": "readme.html#repository-information",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "This is a website for a cognitive psychology research project. The aim of this website is to create and share reproducible research assets throughout the project lifespan. This repository is built with quarto. Source code is available from the github repository for this project."
  }
]