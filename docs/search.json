[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "The purpose of this project is to assess capabilities of LLMs, such as OpenAI’s GPT models, to simulate behavioral data from classic attention and performance tasks in cognitive psychology, like the Stroop task.\nStatus:\n\nIn progress\nExploratory"
  },
  {
    "objectID": "index.html#project-information",
    "href": "index.html#project-information",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "The purpose of this project is to assess capabilities of LLMs, such as OpenAI’s GPT models, to simulate behavioral data from classic attention and performance tasks in cognitive psychology, like the Stroop task.\nStatus:\n\nIn progress\nExploratory"
  },
  {
    "objectID": "index.html#repository-information",
    "href": "index.html#repository-information",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "Repository Information",
    "text": "Repository Information\nThis is a website for a cognitive psychology research project. The aim of this website is to create and share reproducible research assets throughout the project lifespan. This repository is built with quarto. Source code is available from the github repository for this project."
  },
  {
    "objectID": "index.html#dependencies",
    "href": "index.html#dependencies",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "Dependencies:",
    "text": "Dependencies:\nList of R packages used.\n\n# get packages and print version in tibble\ndependencies &lt;- renv::dependencies()\n\nFinding R package dependencies ... Done!\n\nunique_dependencies &lt;- unique(dependencies$Package)\n\ndependency_tibble &lt;- sapply(unique_dependencies,\n       FUN = function(x) as.character(packageVersion(x))) |&gt;\n  tibble::enframe()\n\nknitr::kable(dependency_tibble)\n\n\n\n\nname\nvalue\n\n\n\n\nknitr\n1.42\n\n\nrenv\n0.17.3\n\n\ntibble\n3.1.8\n\n\nrmarkdown\n2.20\n\n\nopenai\n0.4.1\n\n\npatchwork\n1.1.2\n\n\ntidyverse\n1.3.2\n\n\nxtable\n1.8.4\n\n\nstringr\n1.5.0\n\n\npapaja\n0.1.1"
  },
  {
    "objectID": "modeling/S1_basic_stroop.html",
    "href": "modeling/S1_basic_stroop.html",
    "title": "Simulation 1: Basic Stroop",
    "section": "",
    "text": "The goal of simulation 1 is to determine whether or not GPT-3.5-turbo is capable of simulating performance in a standard Stroop task. To accomplish this, the model will be given a text-based Stroop task where it will be shown a word presented in a particular color. On each trial, the model will be instructed to respond as quickly and accurately as possible to identify the color. The response will include the name of the color and a simulated reaction time in milliseconds. To facilitate easy analysis in R, the model is instructed to return results in JSON format."
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#goal",
    "href": "modeling/S1_basic_stroop.html#goal",
    "title": "Simulation 1: Basic Stroop",
    "section": "",
    "text": "The goal of simulation 1 is to determine whether or not GPT-3.5-turbo is capable of simulating performance in a standard Stroop task. To accomplish this, the model will be given a text-based Stroop task where it will be shown a word presented in a particular color. On each trial, the model will be instructed to respond as quickly and accurately as possible to identify the color. The response will include the name of the color and a simulated reaction time in milliseconds. To facilitate easy analysis in R, the model is instructed to return results in JSON format."
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#load-libraries",
    "href": "modeling/S1_basic_stroop.html#load-libraries",
    "title": "Simulation 1: Basic Stroop",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#run-model",
    "href": "modeling/S1_basic_stroop.html#run-model",
    "title": "Simulation 1: Basic Stroop",
    "section": "Run model",
    "text": "Run model\nNotes: 25 simulated subjects. 24 Stroop trials each. 50% congruent/incongruent items made up from combinations of red, green, blue, and yellow. Instructions are minimal: to identify the color as quickly and accurately as possible.\nAdditional note: I had the original intention to randomize the trial list for each simulated subject. However, the code below randomized the list once, and gave all simulated subjects the same list.\nTakes about 10 minutes or so run, maybe less, didn’t time it.\nUsed default params for gpt-3.5-turbo from the openai library.\n\n\nShow the code\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- c(\"The word red printed in the color red\",\n                     \"The word blue printed in the color blue\",\n                     \"The word yellow printed in the color yellow\",\n                     \"The word green printed in the color green\")\n\n# four possible incongruent items\nincongruent_items &lt;- c(\"The word red printed in the color blue\",\n                       \"The word red printed in the color green\",\n                       \"The word red printed in the color yellow\",\n                       \"The word blue printed in the color red\",\n                       \"The word blue printed in the color green\",\n                       \"The word blue printed in the color yellow\",\n                       \"The word yellow printed in the color red\",\n                       \"The word yellow printed in the color blue\",\n                       \"The word yellow printed in the color green\",\n                       \"The word green printed in the color red\",\n                       \"The word green printed in the color blue\",\n                       \"The word green printed in the color yellow\")\n\n# generate 50% congruent and 50% incongruent trials\n# 12 each (congruent and incongruent)\ntrials &lt;- sample(c(rep(congruent_items,3),incongruent_items))\n\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:25){\n  print(i)\n  \n  gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo\",\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Your task is to respond as quickly and accurately as possible, and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste(\"Consider the following trials of a Stroop task where you are supposed to identify the ink-color of the word as quickly and accurately as possible.\",\"-----\", paste(1:24, trials, collapse=\"\\n\") , \"-----\",'This is a simulated Stroop task. You will be shown a Stroop item in the form of a sentence. The sentence will describe a word presented in a particular ink-color. Your task is to identify the ink-color of the word as quickly and accurately as possible. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].', sep=\"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"word\",\"color\",\"response\",\"reaction_time\")) == 5) {\n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_1.RData\")"
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#analysis",
    "href": "modeling/S1_basic_stroop.html#analysis",
    "title": "Simulation 1: Basic Stroop",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_1.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 25 times, but still need to compute the total number of valid simulated subjects.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 23 out of 25 valid simulated subjects.\n\nReaction time analysis\n\n\nShow the code\n# get mean RTs in each condition for each subject\nrt_data_subject_congruency &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n# Compute difference scores for each subject\nrt_data_subject_stroop &lt;- rt_data_subject_congruency %&gt;%\n  pivot_wider(names_from = congruency,\n              values_from = mean_rt) %&gt;%\n  mutate(Stroop_effect = incongruent-congruent)\n\n# make plots\n\nF1A &lt;- ggplot(rt_data_subject_congruency, aes(x = congruency,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  ggtitle(\"A\")\n\nF1B &lt;- ggplot(rt_data_subject_stroop, aes(x = ' ',\n                                   y = Stroop_effect))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Stroop Effects\")+\n  xlab(\"Incongruent - Congruent\")+\n  ggtitle(\"B\")\n\nF1A + F1B\n\n\n\n\n\nFigure 1A shows simulated mean reaction times for congruent and incongruent trials. Individual dots show means at the level of simulated subjects. Figure 1B shows the overall mean Stroop effect and individual mean Stroop effects for each simulated subject. 22 of the 23 simulated subjects showed positive Stroop effects, and one simulated subject showed a reverse Stroop effect.\nThe major take home point is that the LLM is capable of generating data that have grossly similar characteristics to human reaction time data in the Stroop task. First, the model produces faster responses to congruent than incongruent trials. Second, the model generates data patterns stochastically, and individual simulated subjects showed different patterns of reaction time data. The range of reaction time values is not outside the range found in studies with human participants.\n\n\nA closer look at reaction times\nHuman reaction time data is often distributed like a normal distribution with a long tail, also termed an ex-Gaussian distribution. Combining across all of the simulated subjects, what does the histogram of simulated RTs look like? At a group level, the reactions time look almost plausible.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe next histogram changes the binwidth. The simulated RTs are not spaced equally within the distribution. Many of the numbers are too “round”, like 400, 450, 500, etc.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=10, color=\"white\")+\n  scale_x_continuous(breaks=seq(250,1000,50))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe following histogram is a count of the ending digits for each of the simulated reaction times generated by gpt-3.5-turbo. A large majority of the values ended in zero, with five scoring a distance second. One question for future simulations is whether this behavior can be modified by changing the prompt to the model.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#accuracy-analysis",
    "href": "modeling/S1_basic_stroop.html#accuracy-analysis",
    "title": "Simulation 1: Basic Stroop",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(proportion_correct = sum(accuracy)/12, .groups = \"drop\") %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = congruency,\n              values_from = proportion_correct) %&gt;%\n  mutate(Stroop_effect = incongruent-congruent)\n\n\nEvery simulated subject scored 100% accurate on both congruent and incongruent trials."
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#congruency-sequence-effect",
    "href": "modeling/S1_basic_stroop.html#congruency-sequence-effect",
    "title": "Simulation 1: Basic Stroop",
    "section": "Congruency Sequence effect",
    "text": "Congruency Sequence effect\nA common finding in the Stroop literature is that Stroop effects are larger following congruent trials than incongruent trials. This information was not included in the prompt. The purpose of this analysis is to determine whether the LLM generates simulated RT data that also contain congruency sequence effects.\n\n\nShow the code\n# add last trial congruency as a factor\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\"))\n\nall_sim_data$last_trial_congruent &lt;- c(NA,all_sim_data$congruency[1:(dim(all_sim_data)[1]-1)])\n\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(last_trial_congruent = case_when(trial == 1 ~ NA,\n                                          trial != 1 ~ last_trial_congruent)) \n\n# report rt data\nrt_data_subject_seq &lt;- all_sim_data %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE,\n         is.na(last_trial_congruent) == FALSE) %&gt;%\n  mutate(last_trial_congruent = paste0(\"n1\",last_trial_congruent)) %&gt;%\n  group_by(congruency,last_trial_congruent,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\") %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = c(congruency,last_trial_congruent),\n              values_from = mean_rt) %&gt;%\n  mutate(Previous_congruent = incongruent_n1congruent-congruent_n1congruent,\n         Previous_incongruent = incongruent_n1incongruent-congruent_n1incongruent\n         ) %&gt;%\n  pivot_longer(cols = c(\"Previous_congruent\",\"Previous_incongruent\"),\n               names_to = \"Sequential\") %&gt;%\n  mutate(Sequential = as.factor(Sequential)) %&gt;%\n  mutate(Sequential = recode(Sequential,\n                             \"Previous_congruent\" = \"N-1 Congruent\",\n                             \"Previous_incongruent\" = \"N-1 Incongruent\"\n                             ))\n\n# make plots\n\nggplot(rt_data_subject_seq, aes(x = Sequential,\n                                y = value))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Stroop Effect\") +\n  xlab(\"Previous Trial\")\n\n\n\n\n\n\n\nShow the code\n# ANOVA\n\n# ensure factors\nrt_data_subject_seq &lt;- rt_data_subject_seq %&gt;%\n  mutate(sim_subject = factor(sim_subject))\n\n# run ANOVA\naov_sequential &lt;- aov(value ~ Sequential + Error(sim_subject/Sequential), data = rt_data_subject_seq)\n\n# save printable summaries\napa_print &lt;- papaja::apa_print(aov_sequential)\n\nknitr::kable(xtable(summary(aov_sequential)))\n\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nResiduals\n22\n390332.87\n17742.403\nNA\nNA\n\n\nSequential\n1\n46160.66\n46160.657\n20.52313\n0.0001652\n\n\nResiduals\n22\n49482.43\n2249.201\nNA\nNA\n\n\n\n\n\nAuthor’s note: Huh.\nIn this simulation of 23 subjects, the mean Stroop effect was larger for trials preceded by a congruent item compared to trials preceded by an incongruent item, \\(F(1, 22) = 20.52\\), \\(p &lt; .001\\), \\(\\hat{\\eta}^2_G = .095\\), 90% CI \\([.000, .316]\\)."
  },
  {
    "objectID": "modeling/S1_basic_stroop.html#discussion",
    "href": "modeling/S1_basic_stroop.html#discussion",
    "title": "Simulation 1: Basic Stroop",
    "section": "Discussion",
    "text": "Discussion\nGPT-3.5-turbo produced simulated data that approximated human behavior in several respects, including producing standard Stroop effects, and even a congruency sequence effect. The accuracy data was too perfect, and the reaction time data was too round (most numbers ended in zeros.)\nGeneral caveats. This code can be re-run, but the result is not completely reproducible because the LLM is stochastic and will return different answers each time."
  },
  {
    "objectID": "modeling/todo.html",
    "href": "modeling/todo.html",
    "title": "Project Scratchpad",
    "section": "",
    "text": "I’ve already started on the work in a blog post: https://crumplab.com/blog/771_GPT_Stroop/\nNeed to briefly list what I’ve done already.\nThen, come up with some goals for moving the project forward."
  },
  {
    "objectID": "modeling/todo.html#blog-post-summary",
    "href": "modeling/todo.html#blog-post-summary",
    "title": "Project Scratchpad",
    "section": "Blog post summary",
    "text": "Blog post summary\n\nBriefly described the Stroop task\nDevelops some motivation for why I care whether or not LLMs can simulate performance in a Stroop-task\n\ndata-spoofing, such as mturk workers using LLMs to exploit online tasks.\n\nDescribe methods\n\nuse the openai API and R to send instructions for a Stroop task, and then individual trials (in text format)\nhave the model simulate trial-by-trial responses and reaction times, return them in JSON\nanalyse the data and see what happens\n\nThe post shows some draft code to simulate a single subject, and to simulate multiple subjects\nGot data from 10 simulated subjects\nResults showed:\n\ngpt-3.5-turbo generated data files that showed Stroop effects\nSimulated RTs were different across simulated subjects\nAccuracy was 100%\nRTs looked almost credible. Many individual RTs had 0 ending, and were too round looking."
  },
  {
    "objectID": "modeling/todo.html#to-do",
    "href": "modeling/todo.html#to-do",
    "title": "Project Scratchpad",
    "section": "To do",
    "text": "To do\nNot an exhaustive list, something to get me started.\n\nSettle on one script that can be extended across the examples.\nRun multiple subjects, say batches of 20-30, which should be enough for the kinds of questions I want to ask\n\nAnswer the following basic questions\n\nDoes the model produce Stroop effects in RT and accuracy?\nDoes the model produce different answers for each run of simulated subjects?\nDoes the model produce RTs that look like human subject RTs?\nDoes the model produce additional Stroop phenomena without further prompting?\n\nCongruency sequence effect?\nProportion Congruent effect?\n\nCan the instruction prompt be used to control how the model simulates performance.\n\nsimulate 75% correct\n[] simulate 50% correct\nsimulate some long reaction times\nsimulate a reverse Stroop effect.\n[] simulate proportion congruent effects\n\n[] simulate some other tasks\n[] Flanker task\n[] Simon Task\n[] SRT (Nissen & Bullemer)\n[] Negative Priming\n[] Inhibition of Return\n[] SNARC effect"
  },
  {
    "objectID": "modeling/S3_stroop_pc.html",
    "href": "modeling/S3_stroop_pc.html",
    "title": "Pilot Simulation 3: Proportion congruent",
    "section": "",
    "text": "Started Pilot data\nHalf-baked. Successfully ran 14 simulated subjects, but requested 20. May need to refactor the code to allow for longer prompts\nSee Simulation 6 instead."
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#state",
    "href": "modeling/S3_stroop_pc.html#state",
    "title": "Pilot Simulation 3: Proportion congruent",
    "section": "",
    "text": "Started Pilot data\nHalf-baked. Successfully ran 14 simulated subjects, but requested 20. May need to refactor the code to allow for longer prompts\nSee Simulation 6 instead."
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#recap",
    "href": "modeling/S3_stroop_pc.html#recap",
    "title": "Pilot Simulation 3: Proportion congruent",
    "section": "Recap",
    "text": "Recap\nSimulation one showed that GPT-3.5-Turbo can complete a Stroop task presented in the form of text prompts, and generate patterns of data that resemble human performance in several respects. For example, the model generated faster reaction times for congruent than incongruent items. The model generated reactions with inter and intra-subject variability. The model also performed with 100% accuracy, and chose implausibly round numbers. The second simulation varied the prompt to encourage more variability in accuracy and reaction time number generation. The reaction times appeared as if they were sampled from a continuous distribution. Accuracy rates for incongruent items varied across subjects.\nIn simulation 1 the model also generated reaction times that were consistent with congruency sequence effects. Specifically, the simulated Stroop effect from trials preceded by a congruent item was found to be larger than the Stroop effect from trials preceded by an incongruent item. The model was not given instructions regarding the congruency sequence, and it is somewhat intriguing that it generated data consistent with the presence of that effect. One possibility is that the models training corpus contains raw data from Stroop experiments, in which case it may be possible that the model generating data patterns for the present simulations in the style of existing training data.\nI don’t know enough about how the model works, or the data it was trained on, to make strong claims or conclusions about these issues. Nevertheless, these issues are relevant to fleshing out concerns about using LLMs to spoof human data. In this case, the model appears to spoof multiple aspects of human performance in the Stroop task.\nThe purpose of the simulation 3 was to determine whether the model will generate data consistent with list-wide proportion congruent effects, without being prompted to do so."
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#load-libraries",
    "href": "modeling/S3_stroop_pc.html#load-libraries",
    "title": "Pilot Simulation 3: Proportion congruent",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#run-model",
    "href": "modeling/S3_stroop_pc.html#run-model",
    "title": "Pilot Simulation 3: Proportion congruent",
    "section": "Run model",
    "text": "Run model\nNotes: 20 simulated subjects. 32 Stroop trials each. First 10 subjects are given high proportion congruent, last 10 given low proportion congruent.\nUnlike the previous simulations, each subject is given a different randomized order.\nThe new prompt is shown in the code.\nUsed default params for gpt-3.5-turbo from the openai library.\nProblems: This code produced 14 valid JSON files out of 20.\n\n\nShow the code\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- c(\"The word red printed in the color red\",\n                     \"The word blue printed in the color blue\",\n                     \"The word yellow printed in the color yellow\",\n                     \"The word green printed in the color green\")\n\n# four possible incongruent items\nincongruent_items &lt;- c(\"The word red printed in the color blue\",\n                       \"The word red printed in the color green\",\n                       \"The word red printed in the color yellow\",\n                       \"The word blue printed in the color red\",\n                       \"The word blue printed in the color green\",\n                       \"The word blue printed in the color yellow\",\n                       \"The word yellow printed in the color red\",\n                       \"The word yellow printed in the color blue\",\n                       \"The word yellow printed in the color green\",\n                       \"The word green printed in the color red\",\n                       \"The word green printed in the color blue\",\n                       \"The word green printed in the color yellow\")\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:20){\n  print(i)\n  \n  # generate 50% congruent and 50% incongruent trials\n  # 12 each (congruent and incongruent)\n  hpc_trials &lt;-  sample(c(rep(congruent_items,3*2),sample(incongruent_items,8)))\n  lpc_trials &lt;-  sample(c(rep(congruent_items,2),rep(incongruent_items,2)))\n  \n  # choose proportion congruent based on subject number\n  if (i &lt;= 10) {\n    trials &lt;- hpc_trials\n    proportion_congruent &lt;- \"high\"\n  } else {\n    trials &lt;- lpc_trials\n    proportion_congruent &lt;- \"low\"\n  }\n  \n  gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo\",\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste(\"Consider the following trials of a Stroop task where you are supposed to identify the ink-color of the word as quickly and accurately as possible.\",\"-----\", paste(1:32, trials, collapse=\"\\n\") , \"-----\",'This is a simulated Stroop task. You will be shown a Stroop item in the form of a sentence. The sentence will describe a word presented in a particular ink-color. Your task is to identify the ink-color of the word as quickly and accurately as a human participant would. Your simulated reaction times should look like real human data and end in different numbers. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].', sep=\"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"word\",\"color\",\"response\",\"reaction_time\")) == 5) {\n      \n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i,\n               proportion_congruent = proportion_congruent)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_3.RData\")"
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#analysis",
    "href": "modeling/S3_stroop_pc.html#analysis",
    "title": "Pilot Simulation 3: Proportion congruent",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_3.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 20 times.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 14 out of 20 valid simulated subjects.\n\nReaction time analysis\nThis analysis has too few simulated subjects to be meaningful.\n\n\nShow the code\n# get mean RTs in each condition for each subject\nrt_data_subject_congruency &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(proportion_congruent,congruency,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n# make plots\n\nggplot(rt_data_subject_congruency, aes(x = congruency,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  facet_wrap(~proportion_congruent)\n\n\n\n\n\n\n\nA closer look at reaction times\nAs with previous simulations, the reaction times look sort of Ex-Gaussian.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nSetting the bin-wdith smaller shows that the model used many more numbers in between round intervals.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=10, color=\"white\")+\n  scale_x_continuous(breaks=seq(250,1000,50))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe model did produce simulated reaction times that ended in all possible digits. At the same time, it shows a preference for values ending in zero.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#accuracy-analysis",
    "href": "modeling/S3_stroop_pc.html#accuracy-analysis",
    "title": "Pilot Simulation 3: Proportion congruent",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(proportion_correct = mean(accuracy), .groups = \"drop\")\n\nggplot(accuracy_data_subject, aes(x = congruency,\n                                  y = proportion_correct))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Proportion Correct\")+\n  xlab(\"Congruency\")"
  },
  {
    "objectID": "modeling/S3_stroop_pc.html#discussion",
    "href": "modeling/S3_stroop_pc.html#discussion",
    "title": "Pilot Simulation 3: Proportion congruent",
    "section": "Discussion",
    "text": "Discussion\nThis simulation used a slightly longer prompt than the first two simulation. The first two simulations had 24 simulated trials, and this one had 32. I also tried a version with 48 trials per subject, but received 502 gateway errors from the API. I’m not sure whether the prompt was too long, or the expected response was too long."
  },
  {
    "objectID": "modeling/S7_Stroop_task_switching.html",
    "href": "modeling/S7_Stroop_task_switching.html",
    "title": "Simulation 7: Stroop Task Switching",
    "section": "",
    "text": "Started. Finished."
  },
  {
    "objectID": "modeling/S7_Stroop_task_switching.html#state",
    "href": "modeling/S7_Stroop_task_switching.html#state",
    "title": "Simulation 7: Stroop Task Switching",
    "section": "",
    "text": "Started. Finished."
  },
  {
    "objectID": "modeling/S7_Stroop_task_switching.html#recap",
    "href": "modeling/S7_Stroop_task_switching.html#recap",
    "title": "Simulation 7: Stroop Task Switching",
    "section": "Recap",
    "text": "Recap\nThis simulation continues in the direction of determining whether GPT will produce patterns of data typical of human performance in a Stroop task, even for conditions and task demands that are not explicitly prompted.\nSimulation 1 showed that GPT appears to generate data that contain congruency sequence effects. Simulation 2 showed that GPT may generate data sensitive to a list-wide proportion congruent manipulation.\nThis simulation looks at task-switching performance. In a Stroop task it is possible to have participants name the ink-color or the word. Word-naming is generally faster than color naming. People show slower RTs and larger Stroop effects for the color naming task, and overall faster RTs and much smaller Stroop effects for the word naming task. If the instructions are intermixed within a block of trials, then people also show a task-switching effect. Responses are faster when the task repeats across trials, compared to when the task switches across trials."
  },
  {
    "objectID": "modeling/S7_Stroop_task_switching.html#load-libraries",
    "href": "modeling/S7_Stroop_task_switching.html#load-libraries",
    "title": "Simulation 7: Stroop Task Switching",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S7_Stroop_task_switching.html#run-model",
    "href": "modeling/S7_Stroop_task_switching.html#run-model",
    "title": "Simulation 7: Stroop Task Switching",
    "section": "Run model",
    "text": "Run model\nNotes: 15 simulated subjects. 48 Stroop trials each. 50/50 congruent and incongruent trials. Half of the trials are color-naming, the other half are word-naming, randomly intermixed.\nThe prompt does no longer mentions the Stroop effect, instead it mentions word or color naming task.\nUsed gpt-3.5-turbo-16k, with max tokens 10000.\nProblems: Still getting the occasional invalid JSON back, mostly due to the chatbot prefacing its response with a message before the JSON. This thread may be helpful https://community.openai.com/t/getting-response-data-as-a-fixed-consistent-json-response/28471/31?page=2.\n\n\nShow the code\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- data.frame(word  = c(\"red\",\"green\",\"blue\",\"yellow\"),\n                              color = c(\"red\",\"green\",\"blue\",\"yellow\"))\n\n# 12 possible congruent items\nincongruent_items &lt;- data.frame(word  = c(\"red\",\"red\",\"red\",\n                                          \"green\",\"green\",\"green\",\n                                          \"blue\",\"blue\",\"blue\",\n                                          \"yellow\",\"yellow\",\"yellow\"),\n                              color = c(\"green\",\"blue\",\"yellow\",\n                                        \"blue\",\"yellow\",\"red\",\n                                        \"red\",\"yellow\",\"green\",\n                                        \"red\",\"blue\",\"green\"))\n\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:15){\n  print(i)\n  \n  # construct trials data frame\n  congruent_trials &lt;- congruent_items[rep(1:nrow(congruent_items),3),]\n  incongruent_trials &lt;- incongruent_items[rep(1:nrow(incongruent_items),1),]\n\n  trials &lt;- rbind(congruent_trials,\n                  incongruent_trials,\n                  congruent_trials,\n                  incongruent_trials\n                  ) %&gt;%\n    mutate(instruction = rep(c(\"Identify color\",\"Identify word\"),each=24))\n  \n  trials &lt;- trials[sample(1:nrow(trials)),]\n  trials &lt;- trials %&gt;%\n    mutate(trial = 1:nrow(trials),\n           response = \"?\",\n           reaction_time = \"?\") %&gt;%\n    relocate(instruction) %&gt;%\n    relocate(trial)\n  \n   # run the api call to openai\n  \n gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo-16k\",\n   max_tokens = 10000,\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste('You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file. Your task is to simulate human performance in a word and color naming task. You will be the task in the form a JSON object. The JSON object contains the word and color presented on each trial. Your task is to read the task instruction for each trial. If the instruction is to name the color, then identify the color as quickly and accurately as a human would. If the instruction is to name the word, then identify the word as quickly and accurately as a human would. The JSON object contains the symbol ? in locations where you will generate simulated responses. You will generate a simulated identification response, and a simulated reaction time for each trial. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"instruction\" = \"the task instruction, string\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].',\n                       \"\\n\\n\",\n                       jsonlite::toJSON(trials), collapse = \"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  print(gpt_response$usage$total_tokens)\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n  print(test_JSON)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"instruction\",\"word\",\"color\",\"response\",\"reaction_time\")) == 6) {\n      \n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_7.RData\")"
  },
  {
    "objectID": "modeling/S7_Stroop_task_switching.html#analysis",
    "href": "modeling/S7_Stroop_task_switching.html#analysis",
    "title": "Simulation 7: Stroop Task Switching",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_7.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 15 times.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 14 out of 15 valid simulated subjects.\n\nReaction time analysis\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(reaction_time = as.numeric(reaction_time))\n\n# get mean RTs in each condition for each subject\nrt_data_subject_congruency &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(instruction == \"Identify color\" & response == color ~ TRUE,\n                              instruction == \"Identify color\" & response != color ~ FALSE,\n                              instruction == \"Identify word\" & response == word ~ TRUE,\n                              instruction == \"Identify word\" & response != word ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(instruction,congruency,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n# make plots\n\nggplot(rt_data_subject_congruency, aes(x = congruency,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  facet_wrap(~instruction)\n\n\n\n\n\nThe figure shows similarly sized Stroop effects for the color naming and word naming tasks. This is not the kind of pattern that would be expected from human participants.\n\n\nA closer look at reaction times\nThis time the reaction times look like they came from a normal distribution.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe prompt did not specify to produce values with different endings. As with previous simulations, the model prefers values ending in 0.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/S7_Stroop_task_switching.html#accuracy-analysis",
    "href": "modeling/S7_Stroop_task_switching.html#accuracy-analysis",
    "title": "Simulation 7: Stroop Task Switching",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\nThe model performs perfectly on congruent trials, and sometimes imperfectly on incongruent trials.\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(instruction == \"Identify color\" & response == color ~ TRUE,\n                              instruction == \"Identify color\" & response != color ~ FALSE,\n                              instruction == \"Identify word\" & response == word ~ TRUE,\n                              instruction == \"Identify word\" & response != word ~ FALSE)) %&gt;%\n  group_by(instruction,congruency,sim_subject) %&gt;%\n  summarize(proportion_correct = mean(accuracy), .groups = \"drop\")\n\nggplot(accuracy_data_subject, aes(x = congruency,\n                                  y = proportion_correct))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Proportion Correct\")+\n  xlab(\"Congruency\") +\n  facet_wrap(~instruction)"
  },
  {
    "objectID": "modeling/S7_Stroop_task_switching.html#task-switching",
    "href": "modeling/S7_Stroop_task_switching.html#task-switching",
    "title": "Simulation 7: Stroop Task Switching",
    "section": "Task-switching",
    "text": "Task-switching\n\n\nShow the code\n# add last trial congruency as a factor\nall_sim_data$last_trial_task &lt;- c(NA,all_sim_data$instruction[1:(dim(all_sim_data)[1]-1)])\n\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(last_trial_task = case_when(trial == 1 ~ NA,\n                                          trial != 1 ~ last_trial_task)) %&gt;%\n  mutate(switch_type = case_when(instruction == last_trial_task ~ \"repeat\",\n                                 instruction != last_trial_task ~ \"switch\")\n         )\n\n# get mean RTs in each condition for each subject\nrt_data_subject_switch &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(instruction == \"Identify color\" & response == color ~ TRUE,\n                              instruction == \"Identify color\" & response != color ~ FALSE,\n                              instruction == \"Identify word\" & response == word ~ TRUE,\n                              instruction == \"Identify word\" & response != word ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE,\n         is.na(last_trial_task) == FALSE) %&gt;%\n  group_by(switch_type,instruction,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n# make plots\n\nggplot(rt_data_subject_switch, aes(x = switch_type,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  facet_wrap(~instruction)\n\n\n\n\n\nThe model did not generate faster simulated reaction times for repeat than switch trials, which is commonly found in human data.\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(instruction == \"Identify color\" & response == color ~ TRUE,\n                              instruction == \"Identify color\" & response != color ~ FALSE,\n                              instruction == \"Identify word\" & response == word ~ TRUE,\n                              instruction == \"Identify word\" & response != word ~ FALSE)) %&gt;%\n  filter(is.na(last_trial_task) == FALSE) %&gt;%\n  group_by(switch_type,instruction,sim_subject) %&gt;%\n  summarize(proportion_correct = mean(accuracy), .groups = \"drop\")\n\nggplot(accuracy_data_subject, aes(x = switch_type,\n                                  y = proportion_correct))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Proportion Correct\")+\n  xlab(\"Congruency\") +\n  facet_wrap(~instruction)\n\n\n\n\n\nAccuracy was worse for the color identification instructions than the word identification instructions. But, there was no switch effect on accuracy either."
  },
  {
    "objectID": "modeling/S7_Stroop_task_switching.html#discussion",
    "href": "modeling/S7_Stroop_task_switching.html#discussion",
    "title": "Simulation 7: Stroop Task Switching",
    "section": "Discussion",
    "text": "Discussion\nThis simulation asked whether GPT would return side effects that conform to typical patterns in a Stroop, especially when those results are not explicitly prompted. The simulation was given a Stroop task, and instructed to name the word or color on each trial. Human participants would typically show faster word naming than color naming responses, and smaller Stroop effects on word than color naming trials. The model did not produce faster word than color naming responses, nor did it generate smaller Stroop effects for word than color naming trials. Humans typically show faster responses on task-repeat than task-switch trials. The model did not show the task switching effect."
  },
  {
    "objectID": "modeling/S5_df_to_json.html",
    "href": "modeling/S5_df_to_json.html",
    "title": "Pilot Simulation 5: Send and return JSON",
    "section": "",
    "text": "Started. Code seems to work."
  },
  {
    "objectID": "modeling/S5_df_to_json.html#state",
    "href": "modeling/S5_df_to_json.html#state",
    "title": "Pilot Simulation 5: Send and return JSON",
    "section": "",
    "text": "Started. Code seems to work."
  },
  {
    "objectID": "modeling/S5_df_to_json.html#approach",
    "href": "modeling/S5_df_to_json.html#approach",
    "title": "Pilot Simulation 5: Send and return JSON",
    "section": "Approach",
    "text": "Approach\nCreate a dataframe containing the trial-by-trial structure of a Stroop task. Create columns for response and reaction time, put question marks in the rows for those columns. The question marks represent missing data that the model needs to fill in.\nConvert the dataframe to json, and send the json to the model as part of the prompt. Have the model return a json with the simulated data filled in.\nAdditionally, use gpt-3.5-turbo-16k model. This increases the maximum number of tokens."
  },
  {
    "objectID": "modeling/S5_df_to_json.html#load-libraries",
    "href": "modeling/S5_df_to_json.html#load-libraries",
    "title": "Pilot Simulation 5: Send and return JSON",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S5_df_to_json.html#run-model",
    "href": "modeling/S5_df_to_json.html#run-model",
    "title": "Pilot Simulation 5: Send and return JSON",
    "section": "Run model",
    "text": "Run model\n\n\nShow the code\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- data.frame(word  = c(\"red\",\"green\",\"blue\",\"yellow\"),\n                              color = c(\"red\",\"green\",\"blue\",\"yellow\"))\n\n# 12 possible congruent items\nincongruent_items &lt;- data.frame(word  = c(\"red\",\"red\",\"red\",\n                                          \"green\",\"green\",\"green\",\n                                          \"blue\",\"blue\",\"blue\",\n                                          \"yellow\",\"yellow\",\"yellow\"),\n                              color = c(\"green\",\"blue\",\"yellow\",\n                                        \"blue\",\"yellow\",\"red\",\n                                        \"red\",\"yellow\",\"green\",\n                                        \"red\",\"blue\",\"green\"))\n\n# construct data frame\n# generate 50% congruent and 50% incongruent trials\n# 12 each (congruent and incongruent)\n\ncongruent_trials &lt;- congruent_items[rep(1:nrow(congruent_items),3),]\nincongruent_trials &lt;- incongruent_items[rep(1:nrow(incongruent_items),1),]\ntrials &lt;- rbind(congruent_trials,incongruent_trials)\ntrials &lt;- trials[sample(1:nrow(trials)),]\ntrials &lt;- trials %&gt;%\n  mutate(trial = 1:nrow(trials),\n         \"instruction\" = \"Identify color\",\n         response = \"?\",\n         reaction_time = \"?\") %&gt;%\n  relocate(instruction) %&gt;%\n  relocate(trial)\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:2){\n  print(i)\n  \n   # run the api call to openai\n gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo-16k\",\n   max_tokens = 10000,\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste('You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file. Your task is to simulate human performance in Stroop task. You will be shown a Stroop task in the form a JSON object. The JSON object contains the word and color presented on each trial. Your task is to identify the ink-color of the word as quickly and accurately as a human participant would. The JSON object contains the symbol ? in locations where you will generate simulated responses. You will generate a simulated identification response, and a simulated reaction time. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"instruction\" = \"the task instruction, string\" \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].',\n                       \"\\n\\n\",\n                       jsonlite::toJSON(trials), collapse = \"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  print(gpt_response$usage$total_tokens)\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"instruction\",\"word\",\"color\",\"response\",\"reaction_time\")) == 6) {\n      \n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\n#save.image(\"data/simulation_5.RData\")"
  },
  {
    "objectID": "modeling/S8_Stroop_task_switchingB.html",
    "href": "modeling/S8_Stroop_task_switchingB.html",
    "title": "Simulation 8: Stroop Task Switching with explicit instructions",
    "section": "",
    "text": "Started. Finished."
  },
  {
    "objectID": "modeling/S8_Stroop_task_switchingB.html#state",
    "href": "modeling/S8_Stroop_task_switchingB.html#state",
    "title": "Simulation 8: Stroop Task Switching with explicit instructions",
    "section": "",
    "text": "Started. Finished."
  },
  {
    "objectID": "modeling/S8_Stroop_task_switchingB.html#recap",
    "href": "modeling/S8_Stroop_task_switchingB.html#recap",
    "title": "Simulation 8: Stroop Task Switching with explicit instructions",
    "section": "Recap",
    "text": "Recap\nSimulation 7 asked whether GPT would return ancillary effects that conform to typical patterns in a Stroop, especially when those results are not explicitly prompted. The simulation was given a Stroop task, and instructed to name the word or color on each trial. Human participants would typically show faster word naming than color naming responses, and smaller Stroop effects on word than color naming trials. The model did not produce faster word than color naming responses, nor did it generate smaller Stroop effects for word than color naming trials. Humans typically show faster responses on task-repeat than task-switch trials. The model did not show the task switching effect.\nThis simulation adds new information into the prompt to explicitly tell the model about how humans would perform in this version of the task."
  },
  {
    "objectID": "modeling/S8_Stroop_task_switchingB.html#load-libraries",
    "href": "modeling/S8_Stroop_task_switchingB.html#load-libraries",
    "title": "Simulation 8: Stroop Task Switching with explicit instructions",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S8_Stroop_task_switchingB.html#run-model",
    "href": "modeling/S8_Stroop_task_switchingB.html#run-model",
    "title": "Simulation 8: Stroop Task Switching with explicit instructions",
    "section": "Run model",
    "text": "Run model\nNotes: 15 simulated subjects. 48 Stroop trials each. 50/50 congruent and incongruent trials. Half of the trials are color-naming, the other half are word-naming, randomly intermixed.\nThe prompt is modified to explicitly inform the model about how to respond.\nUsed gpt-3.5-turbo-16k, with max tokens 10000.\nProblems: Still getting the occasional invalid JSON back, mostly due to the chatbot prefacing its response with a message before the JSON. This thread may be helpful https://community.openai.com/t/getting-response-data-as-a-fixed-consistent-json-response/28471/31?page=2.\n\n\nShow the code\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- data.frame(word  = c(\"red\",\"green\",\"blue\",\"yellow\"),\n                              color = c(\"red\",\"green\",\"blue\",\"yellow\"))\n\n# 12 possible congruent items\nincongruent_items &lt;- data.frame(word  = c(\"red\",\"red\",\"red\",\n                                          \"green\",\"green\",\"green\",\n                                          \"blue\",\"blue\",\"blue\",\n                                          \"yellow\",\"yellow\",\"yellow\"),\n                              color = c(\"green\",\"blue\",\"yellow\",\n                                        \"blue\",\"yellow\",\"red\",\n                                        \"red\",\"yellow\",\"green\",\n                                        \"red\",\"blue\",\"green\"))\n\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:15){\n  print(i)\n  \n  # construct trials data frame\n  congruent_trials &lt;- congruent_items[rep(1:nrow(congruent_items),3),]\n  incongruent_trials &lt;- incongruent_items[rep(1:nrow(incongruent_items),1),]\n\n  trials &lt;- rbind(congruent_trials,\n                  incongruent_trials,\n                  congruent_trials,\n                  incongruent_trials\n                  ) %&gt;%\n    mutate(instruction = rep(c(\"Identify color\",\"Identify word\"),each=24))\n  \n  trials &lt;- trials[sample(1:nrow(trials)),]\n  trials &lt;- trials %&gt;%\n    mutate(trial = 1:nrow(trials),\n           response = \"?\",\n           reaction_time = \"?\") %&gt;%\n    relocate(instruction) %&gt;%\n    relocate(trial)\n  \n   # run the api call to openai\n  \n gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo-16k\",\n   max_tokens = 10000,\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file. Do not include any explanations, only provide a RFC8259 compliant JSON response.\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste('You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file. Your task is to simulate human performance in a word and color naming task. You will be given the task in the form a JSON object. The JSON object contains the word and color presented on each trial. Your task is to read the task instruction for each trial. If the instruction is to name the color, then identify the color as quickly and accurately as a human would. If the instruction is to name the word, then identify the word as quickly and accurately as a human would. Humans are much faster at naming words than colors. Humans show much larger Stroop effects for naming colors, and very small or nonexistent Stroop effects when naming words. When humans repeat the same task from trial to trial they are faster and more accurate compared to when they switch tasks from trial to trial. When you simulate data make sure it conforms to how humans would perform this task. The JSON object contains the symbol ? in locations where you will generate simulated responses. You will generate a simulated identification response, and a simulated reaction time for each trial. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"instruction\" = \"the task instruction, string\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].', \"\\n\\n\", jsonlite::toJSON(trials), collapse = \"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  print(gpt_response$usage$total_tokens)\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n  print(test_JSON)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"instruction\",\"word\",\"color\",\"response\",\"reaction_time\")) == 6) {\n      \n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_8.RData\")"
  },
  {
    "objectID": "modeling/S8_Stroop_task_switchingB.html#analysis",
    "href": "modeling/S8_Stroop_task_switchingB.html#analysis",
    "title": "Simulation 8: Stroop Task Switching with explicit instructions",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_8.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 15 times.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 14 out of 15 valid simulated subjects.\n\nReaction time analysis\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(reaction_time = as.numeric(reaction_time))\n\n# get mean RTs in each condition for each subject\nrt_data_subject_congruency &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(instruction == \"Identify color\" & response == color ~ TRUE,\n                              instruction == \"Identify color\" & response != color ~ FALSE,\n                              instruction == \"Identify word\" & response == word ~ TRUE,\n                              instruction == \"Identify word\" & response != word ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(instruction,congruency,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n# make plots\n\nggplot(rt_data_subject_congruency, aes(x = congruency,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  facet_wrap(~instruction)\n\n\n\n\n\nThe figure shows similarly sized Stroop effects for the color naming and word naming tasks. This is not the kind of pattern that would be expected from human participants.\n\n\nA closer look at reaction times\nThis time the reaction times look like they came from a normal distribution.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe prompt did not specify to produce values with different endings. As with previous simulations, the model prefers values ending in 0.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/S8_Stroop_task_switchingB.html#accuracy-analysis",
    "href": "modeling/S8_Stroop_task_switchingB.html#accuracy-analysis",
    "title": "Simulation 8: Stroop Task Switching with explicit instructions",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\nThe model performs perfectly on congruent trials, and sometimes imperfectly on incongruent trials.\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(instruction == \"Identify color\" & response == color ~ TRUE,\n                              instruction == \"Identify color\" & response != color ~ FALSE,\n                              instruction == \"Identify word\" & response == word ~ TRUE,\n                              instruction == \"Identify word\" & response != word ~ FALSE)) %&gt;%\n  group_by(instruction,congruency,sim_subject) %&gt;%\n  summarize(proportion_correct = mean(accuracy), .groups = \"drop\")\n\nggplot(accuracy_data_subject, aes(x = congruency,\n                                  y = proportion_correct))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Proportion Correct\")+\n  xlab(\"Congruency\") +\n  facet_wrap(~instruction)"
  },
  {
    "objectID": "modeling/S8_Stroop_task_switchingB.html#task-switching",
    "href": "modeling/S8_Stroop_task_switchingB.html#task-switching",
    "title": "Simulation 8: Stroop Task Switching with explicit instructions",
    "section": "Task-switching",
    "text": "Task-switching\n\n\nShow the code\n# add last trial congruency as a factor\nall_sim_data$last_trial_task &lt;- c(NA,all_sim_data$instruction[1:(dim(all_sim_data)[1]-1)])\n\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(last_trial_task = case_when(trial == 1 ~ NA,\n                                          trial != 1 ~ last_trial_task)) %&gt;%\n  mutate(switch_type = case_when(instruction == last_trial_task ~ \"repeat\",\n                                 instruction != last_trial_task ~ \"switch\")\n         )\n\n# get mean RTs in each condition for each subject\nrt_data_subject_switch &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(instruction == \"Identify color\" & response == color ~ TRUE,\n                              instruction == \"Identify color\" & response != color ~ FALSE,\n                              instruction == \"Identify word\" & response == word ~ TRUE,\n                              instruction == \"Identify word\" & response != word ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE,\n         is.na(last_trial_task) == FALSE) %&gt;%\n  group_by(switch_type,instruction,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n# make plots\n\nggplot(rt_data_subject_switch, aes(x = switch_type,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  facet_wrap(~instruction)\n\n\n\n\n\nThe model did not generate faster simulated reaction times for repeat than switch trials, which is commonly found in human data.\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(instruction == \"Identify color\" & response == color ~ TRUE,\n                              instruction == \"Identify color\" & response != color ~ FALSE,\n                              instruction == \"Identify word\" & response == word ~ TRUE,\n                              instruction == \"Identify word\" & response != word ~ FALSE)) %&gt;%\n  filter(is.na(last_trial_task) == FALSE) %&gt;%\n  group_by(switch_type,instruction,sim_subject) %&gt;%\n  summarize(proportion_correct = mean(accuracy), .groups = \"drop\")\n\nggplot(accuracy_data_subject, aes(x = switch_type,\n                                  y = proportion_correct))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Proportion Correct\")+\n  xlab(\"Congruency\") +\n  facet_wrap(~instruction)\n\n\n\n\n\nAccuracy was worse for the color identification instructions than the word identification instructions. But, there was no switch effect on accuracy either."
  },
  {
    "objectID": "modeling/S8_Stroop_task_switchingB.html#discussion",
    "href": "modeling/S8_Stroop_task_switchingB.html#discussion",
    "title": "Simulation 8: Stroop Task Switching with explicit instructions",
    "section": "Discussion",
    "text": "Discussion\nIn this case explicitly instructing the model with more information about how to perform was not enough have the model generate data that conformed to those instructions. Perhaps additional prompt modification would produce such a result."
  },
  {
    "objectID": "modeling/S4_trial_by_trial.html",
    "href": "modeling/S4_trial_by_trial.html",
    "title": "Pilot Simulation 4: Trial-by-trial",
    "section": "",
    "text": "Started. Seems to be working. Too slow to continue."
  },
  {
    "objectID": "modeling/S4_trial_by_trial.html#state",
    "href": "modeling/S4_trial_by_trial.html#state",
    "title": "Pilot Simulation 4: Trial-by-trial",
    "section": "",
    "text": "Started. Seems to be working. Too slow to continue."
  },
  {
    "objectID": "modeling/S4_trial_by_trial.html#goals",
    "href": "modeling/S4_trial_by_trial.html#goals",
    "title": "Pilot Simulation 4: Trial-by-trial",
    "section": "Goals",
    "text": "Goals\nSimulations 1 - 3 package all of the instructions and task into one prompt, and request that the LLM produce responses to each trial in a JSON response object. Simulation 3 had the longest prompt so far, and the model returned several invalid JSON responses. The openai forums suggest that other users experience similar problems. One solution may be to improve the prompt.\nThis simulation pursues a different solution, which is to present the model with one trial at a time, and then ask the model to return a JSON object for each trial, one at a time. I already tried something like this in my blog post, and am going to try again and see what happens.\nThis approach will likely also cause the whole process to take much longer than before."
  },
  {
    "objectID": "modeling/S4_trial_by_trial.html#load-libraries",
    "href": "modeling/S4_trial_by_trial.html#load-libraries",
    "title": "Pilot Simulation 4: Trial-by-trial",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S4_trial_by_trial.html#run-model",
    "href": "modeling/S4_trial_by_trial.html#run-model",
    "title": "Pilot Simulation 4: Trial-by-trial",
    "section": "Run model",
    "text": "Run model\n\n\nShow the code\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- c(\"The word red printed in the color red\",\n                     \"The word blue printed in the color blue\",\n                     \"The word yellow printed in the color yellow\",\n                     \"The word green printed in the color green\")\n\n# four possible incongruent items\nincongruent_items &lt;- c(\"The word red printed in the color blue\",\n                       \"The word red printed in the color green\",\n                       \"The word red printed in the color yellow\",\n                       \"The word blue printed in the color red\",\n                       \"The word blue printed in the color green\",\n                       \"The word blue printed in the color yellow\",\n                       \"The word yellow printed in the color red\",\n                       \"The word yellow printed in the color blue\",\n                       \"The word yellow printed in the color green\",\n                       \"The word green printed in the color red\",\n                       \"The word green printed in the color blue\",\n                       \"The word green printed in the color yellow\")\n\n# generate 50% congruent and 50% incongruent trials\n# 12 each (congruent and incongruent)\ntrials &lt;- sample(c(rep(congruent_items,3),incongruent_items))\n\n\n#set up variables to store data\nsim_data &lt;- tibble()\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# starting message\n\nsim_task &lt;- list(\n       list(\"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Your task is to respond as quickly and accurately as possible, and record your simulated responses in JSON. The JSON object should only contain the results for the current trial.\"),\n       list(\"role\" = \"assistant\",\n           \"content\" = \"OK, what are the instructions for this task?\"),\n       list(\"role\" = \"user\",\n           \"content\" = 'This is a simulated Stroop task. You will be shown a Stroop item in the form of a sentence. The sentence will describe a word presented in a particular ink-color. Your task is to identify the ink-color of the word as quickly and accurately as possible. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].'),\n       list(\"role\" = \"assistant\",\n           \"content\" = \"OK, show the next trial.\")\n       )\n\ntask_names &lt;- c(\"trial\",\"word\",\"color\",\"response\",\"reaction_time\")\n\nfor(i in 1:10){\n  \n  print(i)\n  \n  # add trial to list of messages\n  sim_task[[length(sim_task)+1]] &lt;- list(\n    \"role\" = \"user\",\n    \"content\" = trials[i]\n  )\n  \n  # get response\n  gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo\",\n   messages = sim_task\n   )\n  \n  #validate json and proceed\n  \n  if(jsonlite::validate(as.character(gpt_response$choices$message.content)) == TRUE){\n    \n    # convert JSON to tibble\n    trial_tibble &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    print(trial_tibble)\n    \n    # check if tibble has correct names\n    if(all(task_names == names(trial_tibble))){\n      \n      #add new row to sim\n      sim_data &lt;- rbind(sim_data,trial_tibble)\n      \n      ## response to to message list\n      sim_task[[length(sim_task)+1]] &lt;- list(\n        \"role\" = gpt_response$choices$message.role,\n        \"content\" = gpt_response$choices$message.content\n      )\n    }\n  }\n  \n}\n\n# model responses are in JSON format\n#save.image(\"data/simulation_4.RData\")"
  },
  {
    "objectID": "modeling/S6_stroop_pc.html",
    "href": "modeling/S6_stroop_pc.html",
    "title": "Simulation 6: Proportion congruent",
    "section": "",
    "text": "Started. Finished."
  },
  {
    "objectID": "modeling/S6_stroop_pc.html#state",
    "href": "modeling/S6_stroop_pc.html#state",
    "title": "Simulation 6: Proportion congruent",
    "section": "",
    "text": "Started. Finished."
  },
  {
    "objectID": "modeling/S6_stroop_pc.html#recap",
    "href": "modeling/S6_stroop_pc.html#recap",
    "title": "Simulation 6: Proportion congruent",
    "section": "Recap",
    "text": "Recap\nSimulation 3 attempted to model the list-wide proportion congruent effect. The code frequently returned invalid JSON.\nThis simulation used the approach from simulation 5, which appears to allow longer prompts that return valid JSON with higher frequency."
  },
  {
    "objectID": "modeling/S6_stroop_pc.html#load-libraries",
    "href": "modeling/S6_stroop_pc.html#load-libraries",
    "title": "Simulation 6: Proportion congruent",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S6_stroop_pc.html#run-model",
    "href": "modeling/S6_stroop_pc.html#run-model",
    "title": "Simulation 6: Proportion congruent",
    "section": "Run model",
    "text": "Run model\nNotes: 30 simulated subjects. 48 Stroop trials each. Odd numbered subjects are given high proportion congruent list, even numbered are given low proportion congruent list.\nStarted at 1:26pm finished at 1:56pm\nTotal tokens per prompt ranged from 3500 to 4200+.\nUnlike the previous simulations, each subject is given a different randomized order.\nUsed gpt-3.5-turbo-16k, with max tokens 10000.\nProblems: This code produced 28 valid JSON files out of 30. Much better than last time. And, the prompt had a typo (that I have left in the code).\n## typo\n\"instruction\" = \"the task instruction, string\" \"word\": \"the name of the word\n\n## added comma\n\"instruction\" = \"the task instruction, string\", \"word\": \"the name of the word\nThe two invalid returns were cases where the model was being chatty, and rather than only returning JSON, it also included a preface, like, “Here is my response…”. And, I haven’t written error checking code to find possible JSON inside a text response. It’s possible the two invalid cases actually have valid JSON in the text response. The data should be in gpt_response_list.\n\n\nShow the code\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- data.frame(word  = c(\"red\",\"green\",\"blue\",\"yellow\"),\n                              color = c(\"red\",\"green\",\"blue\",\"yellow\"))\n\n# 12 possible congruent items\nincongruent_items &lt;- data.frame(word  = c(\"red\",\"red\",\"red\",\n                                          \"green\",\"green\",\"green\",\n                                          \"blue\",\"blue\",\"blue\",\n                                          \"yellow\",\"yellow\",\"yellow\"),\n                              color = c(\"green\",\"blue\",\"yellow\",\n                                        \"blue\",\"yellow\",\"red\",\n                                        \"red\",\"yellow\",\"green\",\n                                        \"red\",\"blue\",\"green\"))\n\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:30){\n  print(i)\n  \n  # construct trials data frame\n\n  if (i %% 2 == 1) {\n    proportion_congruent &lt;- \"high\"\n    congruent_trials &lt;- congruent_items[rep(1:nrow(congruent_items),3*3),]\n    incongruent_trials &lt;- incongruent_items[rep(1:nrow(incongruent_items),1),]\n    \n  } else {\n    proportion_congruent &lt;- \"low\"\n    congruent_trials &lt;- congruent_items[rep(1:nrow(congruent_items),3),]\n    incongruent_trials &lt;- incongruent_items[rep(1:nrow(incongruent_items),3),]\n  }\n  \n  trials &lt;- rbind(congruent_trials,incongruent_trials)\n  trials &lt;- trials[sample(1:nrow(trials)),]\n  trials &lt;- trials %&gt;%\n    mutate(trial = 1:nrow(trials),\n           \"instruction\" = \"Identify color\",\n           response = \"?\",\n           reaction_time = \"?\") %&gt;%\n    relocate(instruction) %&gt;%\n    relocate(trial)\n  \n   # run the api call to openai\n  \n gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo-16k\",\n   max_tokens = 10000,\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste('You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file. Your task is to simulate human performance in Stroop task. You will be shown a Stroop task in the form a JSON object. The JSON object contains the word and color presented on each trial. Your task is to identify the ink-color of the word as quickly and accurately as a human participant would. The JSON object contains the symbol ? in locations where you will generate simulated responses. You will generate a simulated identification response, and a simulated reaction time. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"instruction\" = \"the task instruction, string\" \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].',\n                       \"\\n\\n\",\n                       jsonlite::toJSON(trials), collapse = \"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  print(gpt_response$usage$total_tokens)\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n  print(test_JSON)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"instruction\",\"word\",\"color\",\"response\",\"reaction_time\")) == 6) {\n      \n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i,\n               proportion_congruent = proportion_congruent)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_6.RData\")"
  },
  {
    "objectID": "modeling/S6_stroop_pc.html#analysis",
    "href": "modeling/S6_stroop_pc.html#analysis",
    "title": "Simulation 6: Proportion congruent",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_6.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 20 times.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 26 out of 30 valid simulated subjects. Two of the simulations returned invalid JSON, and two of them returned JSON with the wrong headers for the data frame.\n\nReaction time analysis\n\n\nShow the code\n# get mean RTs in each condition for each subject\nrt_data_subject_congruency &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(proportion_congruent,congruency,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n# make plots\n\nggplot(rt_data_subject_congruency, aes(x = congruency,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  facet_wrap(~proportion_congruent)\n\n\n\n\n\nThe figure shows a larger mean Stroop effect for the simulated subjects in the high proportion than low proportion congruent conditions.\n\n\nA closer look at reaction times\nAs with previous simulations, the reaction times look sort of Ex-Gaussian, and this time there appears to be some large outliers.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe prompt did not specify to produce values with different endings. As with previous simulations, the model seems to prefer values ending in 0.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/S6_stroop_pc.html#accuracy-analysis",
    "href": "modeling/S6_stroop_pc.html#accuracy-analysis",
    "title": "Simulation 6: Proportion congruent",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\nThe model performs perfectly on congruent trials, and sometimes imperfectly on incongruent trials.\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(proportion_correct = mean(accuracy), .groups = \"drop\")\n\nggplot(accuracy_data_subject, aes(x = congruency,\n                                  y = proportion_correct))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Proportion Correct\")+\n  xlab(\"Congruency\")"
  },
  {
    "objectID": "modeling/S6_stroop_pc.html#discussion",
    "href": "modeling/S6_stroop_pc.html#discussion",
    "title": "Simulation 6: Proportion congruent",
    "section": "Discussion",
    "text": "Discussion\nThis simulation used GPT-3.5-turbo-16k, and a slightly different prompt strategy. The model successfully returned valid JSON 28 out of 30 simulations.\nOne half of the simulated subjects received a list of 48 Stroop items that was 75% congruent. The other half received a list of 48 Stroop items that was 25% congruent. The model was not given any information about the proportion congruent manipulation in the prompt.\nThe results appear to show a larger Stroop effect for the high then low proportion congruent condition, which is the same finding consistently reported in the human cognition literature. I did not attempt to replicate this result with the model, and it is not clear if the model would consistently reproduce this result over several iterations."
  },
  {
    "objectID": "modeling/S9_flanker.html",
    "href": "modeling/S9_flanker.html",
    "title": "Simulation 9: Flanker Task",
    "section": "",
    "text": "Started. Finished"
  },
  {
    "objectID": "modeling/S9_flanker.html#state",
    "href": "modeling/S9_flanker.html#state",
    "title": "Simulation 9: Flanker Task",
    "section": "",
    "text": "Started. Finished"
  },
  {
    "objectID": "modeling/S9_flanker.html#recap",
    "href": "modeling/S9_flanker.html#recap",
    "title": "Simulation 9: Flanker Task",
    "section": "Recap",
    "text": "Recap\nThe previous simulations focused on the Stroop task. This simulation uses a version of the Eriksen Flanker task."
  },
  {
    "objectID": "modeling/S9_flanker.html#load-libraries",
    "href": "modeling/S9_flanker.html#load-libraries",
    "title": "Simulation 9: Flanker Task",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S9_flanker.html#run-model",
    "href": "modeling/S9_flanker.html#run-model",
    "title": "Simulation 9: Flanker Task",
    "section": "Run model",
    "text": "Run model\nNotes: 15 simulated subjects. 20 Flanker trials each. 50/50 congruent and incongruent trials.\nThe prompt is given only basic information to complete the task.\nUsed gpt-3.5-turbo-16k, with max tokens 10000.\nProblems: Still getting the occasional invalid JSON back, mostly due to the chatbot prefacing its response with a message before the JSON. This thread may be helpful https://community.openai.com/t/getting-response-data-as-a-fixed-consistent-json-response/28471/31?page=2.\n\n\nShow the code\n# Use letters H and F\n\ncompatible_items &lt;- data.frame(stimulus = c(\"HHHHH\",\n                                           \"FFFFF\"),\n                               response = \"?\",\n                               reaction_time = \"?\")\n\nincompatible_items &lt;- data.frame(stimulus = c(\"FFHFF\",\n                                           \"HHFHH\"),\n                                 response = \"?\",\n                                 reaction_time = \"?\")\n\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:15){\n  print(i)\n  \n  # construct trials data frame\n  compatible_trials &lt;- compatible_items[rep(1:nrow(compatible_items),5),]\n  incompatible_trials &lt;- incompatible_items[rep(1:nrow(incompatible_items),5),]\n\n  trials &lt;- rbind(compatible_trials,\n                  incompatible_trials\n                  ) %&gt;%\n    mutate(instruction = \"Identify center letter\")\n  \n  trials &lt;- trials[sample(1:nrow(trials)),]\n  trials &lt;- trials %&gt;%\n    mutate(trial = 1:nrow(trials)) %&gt;%\n    relocate(instruction) %&gt;%\n    relocate(trial)\n  \n   # run the api call to openai\n  \n gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo-16k\",\n   max_tokens = 10000,\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file. Do not include any explanations, only provide a RFC8259 compliant JSON response.\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste('You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in JSON. Your task is to simulate human performance in a letter identification task. You will be given the task in the form a JSON object. The JSON object contains the task instruction and the stimulus on each trial. Your task is to follow the instruction and respond to the stimulus as quickly and accurately as a human participant would. When you simulate data make sure it conforms to how humans would perform this task. The JSON object contains the symbol ? in locations where you will generate simulated responses. You will generate a simulated identification response, and a simulated reaction time for each trial. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"instruction\" = \"the task instruction, string\", \"stimulus\": \"the stimulus, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].', \"\\n\\n\", jsonlite::toJSON(trials), collapse = \"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  print(gpt_response$usage$total_tokens)\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n  print(test_JSON)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"instruction\",\"stimulus\",\"response\",\"reaction_time\")) == 5) {\n      \n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_9.RData\")"
  },
  {
    "objectID": "modeling/S9_flanker.html#analysis",
    "href": "modeling/S9_flanker.html#analysis",
    "title": "Simulation 9: Flanker Task",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_9.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 15 times.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 14 out of 15 valid simulated subjects.\n\nReaction time analysis\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(reaction_time = as.numeric(reaction_time))\n\n# get mean RTs in each condition for each subject\nrt_data_subject_congruency &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(stimulus %in% c(\"HHHHH\",\"FFFFF\") ~ \"congruent\",\n                                stimulus %in% c(\"HHFHH\",\"FFHFF\") ~ \"incongruent\")\n         )%&gt;%\n  rowwise() %&gt;%\n  mutate(center_letter = stringr::str_split(stimulus,\"\")[[1]][3]) %&gt;%\n  as.data.frame() %&gt;%\n  mutate(accuracy = case_when(center_letter == response ~ TRUE,\n                              center_letter != response ~ FALSE\n                              )\n         ) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n\n# Compute difference scores for each subject\nrt_data_subject_flanker &lt;- rt_data_subject_congruency %&gt;%\n  pivot_wider(names_from = congruency,\n              values_from = mean_rt) %&gt;%\n  mutate(Flanker_effect = incongruent-congruent)\n\n# make plots\n\nF1A &lt;- ggplot(rt_data_subject_congruency, aes(x = congruency,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  ggtitle(\"A\")\n\nF1B &lt;- ggplot(rt_data_subject_flanker, aes(x = ' ',\n                                   y = Flanker_effect))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Flanker Effects\")+\n  xlab(\"Incongruent - Congruent\")+\n  ggtitle(\"B\")\n\nF1A + F1B\n\n\n\n\n\nThe figure shows that mean reaction times were faster for congruent than incongruent flanker items. Also, 11 out of 14 simulated subjects showed a positive flanker effect.\n\n\nA closer look at reaction times\nHere is a histogram of the individual simulated reaction times.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe prompt did not specify to produce values with different endings. As with previous simulations, the model prefers values ending in 0.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/S9_flanker.html#accuracy-analysis",
    "href": "modeling/S9_flanker.html#accuracy-analysis",
    "title": "Simulation 9: Flanker Task",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\nThe model performs perfectly on congruent trials, and sometimes imperfectly on incongruent trials.\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(stimulus %in% c(\"HHHHH\",\"FFFFF\") ~ \"congruent\",\n                                stimulus %in% c(\"HHFHH\",\"FFHFF\") ~ \"incongruent\")\n         )%&gt;%\n  rowwise() %&gt;%\n  mutate(center_letter = stringr::str_split(stimulus,\"\")[[1]][3]) %&gt;%\n  as.data.frame() %&gt;%\n  mutate(accuracy = case_when(center_letter == response ~ TRUE,\n                              center_letter != response ~ FALSE\n                              )\n         ) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(proportion_correct = mean(accuracy), .groups = \"drop\")\n\nggplot(accuracy_data_subject, aes(x = congruency,\n                                  y = proportion_correct))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Proportion Correct\")+\n  xlab(\"Congruency\")"
  },
  {
    "objectID": "modeling/S9_flanker.html#discussion",
    "href": "modeling/S9_flanker.html#discussion",
    "title": "Simulation 9: Flanker Task",
    "section": "Discussion",
    "text": "Discussion\nThis simulation produced results that reflected patterns in Flanker data, especially at the level of group and subject means. Individual reaction times are again too round (ending in zero). Accuracy rates are too perfect for congruent items.\nIt remains frustrating that the GPT model is stochastic, and that these results are not reproducible. I could run several batches with larger N to determine whether this result is somewhat stable, but this wouldn’t guarantee the same results could be produced at a later date because the underlying model may change at any time."
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html",
    "href": "modeling/S2_stroop_instructions.html",
    "title": "Simulation 2: Stroop instructions",
    "section": "",
    "text": "Simulation 1 showed that several aspects of trial-to-trial performance in a Stroop task can be simulated by gpt-3.5-turbo. However, some aspects of performance were too good to be human. First, the model produced perfect responses on all trials. Second, the simulated reaction time values were too round, and usually ended in zero or five. Simulation 2 determines whether changes to the prompt instructions can deliver different patterns of results. The prompt will include instructions to perform with accuracy rates between 85% and 95%. The prompt will also include instructions to generate reaction time results that end in any number."
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html#goal",
    "href": "modeling/S2_stroop_instructions.html#goal",
    "title": "Simulation 2: Stroop instructions",
    "section": "",
    "text": "Simulation 1 showed that several aspects of trial-to-trial performance in a Stroop task can be simulated by gpt-3.5-turbo. However, some aspects of performance were too good to be human. First, the model produced perfect responses on all trials. Second, the simulated reaction time values were too round, and usually ended in zero or five. Simulation 2 determines whether changes to the prompt instructions can deliver different patterns of results. The prompt will include instructions to perform with accuracy rates between 85% and 95%. The prompt will also include instructions to generate reaction time results that end in any number."
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html#load-libraries",
    "href": "modeling/S2_stroop_instructions.html#load-libraries",
    "title": "Simulation 2: Stroop instructions",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html#run-model",
    "href": "modeling/S2_stroop_instructions.html#run-model",
    "title": "Simulation 2: Stroop instructions",
    "section": "Run model",
    "text": "Run model\nNotes: 25 simulated subjects. 24 Stroop trials each. 50% congruent/incongruent items made up from combinations of red, green, blue, and yellow.\nThe new prompt is shown in the code.\nTiming it this time. Started at 3:10. Took about 14 minutes.\nUsed default params for gpt-3.5-turbo from the openai library.\n\n\nShow the code\n# use the colors red, green, blue, and yellow\n\n# four possible congruent items\ncongruent_items &lt;- c(\"The word red printed in the color red\",\n                     \"The word blue printed in the color blue\",\n                     \"The word yellow printed in the color yellow\",\n                     \"The word green printed in the color green\")\n\n# four possible incongruent items\nincongruent_items &lt;- c(\"The word red printed in the color blue\",\n                       \"The word red printed in the color green\",\n                       \"The word red printed in the color yellow\",\n                       \"The word blue printed in the color red\",\n                       \"The word blue printed in the color green\",\n                       \"The word blue printed in the color yellow\",\n                       \"The word yellow printed in the color red\",\n                       \"The word yellow printed in the color blue\",\n                       \"The word yellow printed in the color green\",\n                       \"The word green printed in the color red\",\n                       \"The word green printed in the color blue\",\n                       \"The word green printed in the color yellow\")\n\n# generate 50% congruent and 50% incongruent trials\n# 12 each (congruent and incongruent)\ntrials &lt;- sample(c(rep(congruent_items,3),incongruent_items))\n\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:25){\n  print(i)\n  \n  gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo\",\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste(\"Consider the following trials of a Stroop task where you are supposed to identify the ink-color of the word as quickly and accurately as possible.\",\"-----\", paste(1:24, trials, collapse=\"\\n\") , \"-----\",'This is a simulated Stroop task. You will be shown a Stroop item in the form of a sentence. The sentence will describe a word presented in a particular ink-color. Your task is to identify the ink-color of the word as quickly and accurately as a human participant would. Your simulated accuracy should be between 80 and 95 percent accurate. Your simulated reaction times should look like real human data and end in different numbers. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"word\": \"the name of the word, string\",\"color\": \"the color of the word, string\",\"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].', sep=\"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"word\",\"color\",\"response\",\"reaction_time\")) == 5) {\n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_2.RData\")"
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html#analysis",
    "href": "modeling/S2_stroop_instructions.html#analysis",
    "title": "Simulation 2: Stroop instructions",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_2.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 25 times, but still need to compute the total number of valid simulated subjects.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 25 out of 25 valid simulated subjects.\n\nReaction time analysis\n\n\nShow the code\n# get mean RTs in each condition for each subject\nrt_data_subject_congruency &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n# Compute difference scores for each subject\nrt_data_subject_stroop &lt;- rt_data_subject_congruency %&gt;%\n  pivot_wider(names_from = congruency,\n              values_from = mean_rt) %&gt;%\n  mutate(Stroop_effect = incongruent-congruent)\n\n# make plots\n\nF1A &lt;- ggplot(rt_data_subject_congruency, aes(x = congruency,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  ggtitle(\"A\")\n\nF1B &lt;- ggplot(rt_data_subject_stroop, aes(x = ' ',\n                                   y = Stroop_effect))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Stroop Effects\")+\n  xlab(\"Incongruent - Congruent\")+\n  ggtitle(\"B\")\n\nF1A + F1B\n\n\n\n\n\nFigure 1A shows simulated mean reaction times for congruent and incongruent trials. Individual dots show means at the level of simulated subjects. Figure 1B shows the overall mean Stroop effect and individual mean Stroop effects for each simulated subject. The results are similar to Simulation 1.\n\n\nA closer look at reaction times\nThe new prompt included the instructions: “Your simulated accuracy should be between 80 and 95 percent accurate. Your simulated reaction times should look like real human data and end in different numbers.” A major question for simulation 2 was to determine if this prompt would cause the model to generate less round numbers.\nThe histogram looks more like an ex-Gaussian than simulation 1.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nSetting the bin-width smaller shows that the model used many more numbers in between round intervals.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=10, color=\"white\")+\n  scale_x_continuous(breaks=seq(250,1000,50))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe following histogram is a count of the ending digits for each of the simulated reaction times generated by gpt-3.5-turbo. The new prompt was effective in causing the model to produce numbers with all possible endings.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html#accuracy-analysis",
    "href": "modeling/S2_stroop_instructions.html#accuracy-analysis",
    "title": "Simulation 2: Stroop instructions",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\nAnother major question was whether the new prompt would cause less than perfect accuracy on all trials. The model remained 100% accurate on congruent trials, but produced a variety of accuracy rates for incongruent trials.\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(congruency = case_when(word == color ~ \"congruent\",\n                                word != color ~ \"incongruent\")) %&gt;%\n  mutate(accuracy = case_when(response == color ~ TRUE,\n                              response != color ~ FALSE)) %&gt;%\n  group_by(congruency,sim_subject) %&gt;%\n  summarize(proportion_correct = sum(accuracy)/12, .groups = \"drop\")\n\nggplot(accuracy_data_subject, aes(x = congruency,\n                                  y = proportion_correct))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Proportion Correct\")+\n  xlab(\"Congruency\")\n\n\n\n\n\nThe accuracy rates for incongruent items have a clear stepped, almost equal interval like pattern. The prompt succeeded in producing imperfect accuracy rates, but the model did not comply with the instruction to produce accuracy rates between 80-95 percent correct."
  },
  {
    "objectID": "modeling/S2_stroop_instructions.html#discussion",
    "href": "modeling/S2_stroop_instructions.html#discussion",
    "title": "Simulation 2: Stroop instructions",
    "section": "Discussion",
    "text": "Discussion\nThe purpose of Simulation 2 was to determine if simple changes to the instructions would influence the simulated results. The goal was to produce reaction times that appeared more random and ex-Gaussian, as well as more inaccurate responses. In Simulation 2, the reaction times were indeed more random and ex-Gaussian compared to Simulation 1. While the accuracy rates for congruent items remained perfect, there was a wide range of accuracy rates for incongruent items."
  },
  {
    "objectID": "readme.html",
    "href": "readme.html",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "The purpose of this project is to assess capabilities of LLMs, such as OpenAI’s gpt models, to simulate behavioral data from classic attention and performance tasks in cognitive psychology, like the Stroop task.\nStatus:\n\nIn progress\nExploratory\n\n\n\n\nThis is a website for a cognitive psychology research project. The aim of this website is to create and share reproducible research assets throughout the project lifespan. This repository is built with quarto. Source code is available from the github repository for this project."
  },
  {
    "objectID": "readme.html#project-information",
    "href": "readme.html#project-information",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "The purpose of this project is to assess capabilities of LLMs, such as OpenAI’s gpt models, to simulate behavioral data from classic attention and performance tasks in cognitive psychology, like the Stroop task.\nStatus:\n\nIn progress\nExploratory"
  },
  {
    "objectID": "readme.html#repository-information",
    "href": "readme.html#repository-information",
    "title": "Simulating Attention and Performance tasks with an LLM",
    "section": "",
    "text": "This is a website for a cognitive psychology research project. The aim of this website is to create and share reproducible research assets throughout the project lifespan. This repository is built with quarto. Source code is available from the github repository for this project."
  },
  {
    "objectID": "writing/Interim_overview.html",
    "href": "writing/Interim_overview.html",
    "title": "Interim Overview",
    "section": "",
    "text": "Tip\n\n\n\nThis project and summary are works in progress and may be subject to changes until the project is completed."
  },
  {
    "objectID": "writing/Interim_overview.html#motivation-why-am-i-doing-this",
    "href": "writing/Interim_overview.html#motivation-why-am-i-doing-this",
    "title": "Interim Overview",
    "section": "Motivation: Why am I doing this?",
    "text": "Motivation: Why am I doing this?\nI’m not prepared to flesh this section out today, so it is a promise for the future. I developed some of the motivation for this project in a blog post:\nhttps://crumplab.com/blog/771_GPT_Stroop/\nElements of the motivation include:\n\nPersonal curiosity and an excuse to try programmatically interacting with the OpenAI API.\nGeneral concerns about LLMs being used to spoof human data in online situations, such as recent reports that MTurk workers are using LLMs to respond to HITs. I’ve noticed similar behavior in some of my own MTurk requests.\nWondering whether an LLM could fake data in the tasks I typically run online. These tasks are usually programmed in JsPsych and require speeded identification responses on a trial-by-trial basis."
  },
  {
    "objectID": "writing/Interim_overview.html#what-is-this-project",
    "href": "writing/Interim_overview.html#what-is-this-project",
    "title": "Interim Overview",
    "section": "What is this project?",
    "text": "What is this project?\nIn this project I am asking general questions about whether large language models, such as OpenAI’s gpt-3.5-turbo, can spoof human-like data in attention and performance tasks. The simulations so far use a text-based version of the Stroop task.\nThe figure below shows examples of Stroop stimuli that might be presented to people. The task typically involves naming the ink color of the word and avoiding naming the actual word. Responses are usually faster for congruent items, where the color matches the word, compared to incongruent item types, where the color mismatches the word.\n\nThe general question for this project was, what happens if I ask a GPT model to perform a Stroop task?\nI’m using a number of tools that greatly facilitate my ability to ask this kind of question. These include R, an R library for interfacing with the OpenAI API, and the ability of GPT models to return their responses in JSON (most of the time), which makes it easy to analyze simulated responses in R.\nThe details of the simulations run so far can be found on their respective pages in the modeling section. The approach is basically to prompt the model that it is about to perform a Stroop task. I provide trial-by-trial text saying what kind of item is presented on each trial (e.g., the word blue is written in the color red), and I ask the model to identify the color, and provide a simulated reaction time in milliseconds."
  },
  {
    "objectID": "writing/Interim_overview.html#what-happened-so-far",
    "href": "writing/Interim_overview.html#what-happened-so-far",
    "title": "Interim Overview",
    "section": "What happened so far?",
    "text": "What happened so far?\nThe TLDR is that GPT can spoof Stroop data in several ways, and even in some interesting ways. The prompts I used have tell-tale signs that the data was generated by an LLM. Sometimes prompt modifications change the simulated behavior, and sometimes they did not. Let’s review the simulations. All of the details for each simulation can be found in their respective pages in the modeling section."
  },
  {
    "objectID": "writing/Interim_overview.html#simulation-1-basic-stroop",
    "href": "writing/Interim_overview.html#simulation-1-basic-stroop",
    "title": "Interim Overview",
    "section": "Simulation 1: Basic Stroop",
    "text": "Simulation 1: Basic Stroop\nThis simulation used a prompt like:\n\nConsider the following trials of a Stroop task where you are supposed to identify the ink-color of the word as quickly and accurately as possible:\nThe word red printed in the color blue\nThe word red printed in the color green\nThe word red printed in the color yellow\n…etc. for 24 trials.\nThis is a simulated Stroop task. You will be shown a Stroop item in the form of a sentence. The sentence will describe a word presented in a particular ink-color. Your task is to identify the ink-color of the word as quickly and accurately as possible. Put the simulated identification response and reaction time into a JSON array using this format: [{“trial”: “trial number, integer”, “word”: “the name of the word, string”,“color”: “the color of the word, string”,“response”: “the simulated identification response, string”,“reaction_time”: “the simulated reaction time, milliseconds an integer”}].\n\nThe model produced valid JSON files that I could read into R 23 out of 25 times. The simulated data is in the form of a data frame with responses and reaction times for every trial, for each simulated subject. I read the simulated data into R, then analysed the data to determine whether or not the LLM would produce a Stroop effect. Specifically, would it generate fake reaction times that were on average faster for congruent than incongruent trials?\nThe answer is yes, these are the results from the model. In addition to simulating faster mean reaction times for congruent than incongruent items, it also produced different results for each simulated subject. These aspects of the data were not explicitly prompted, or at least I didn’t think I explicitly prompted them.\n\nThe model also generated really unrealistic numbers for reaction times at the level of individual trials. Almost all of the numbers were too rounded, as they ended in 0 or 5, mostly 0. Additionally, the model achieved 100% accuracy on all trials.\nA curious finding was that the model also produced a congruency sequence effect. A common finding in the Stroop literature is that Stroop effects are larger following congruent trials than incongruent trials. Information about this phenomenon was not included in the prompt. Nevertheless, when I analyzed the data for the effect, it showed up.\n\nIt’s possible that this is a spurious finding, I don’t know. The lack of computational reproducibility in this kind of modeling work is very frustrating. It’s possible that the model was trained on raw data from human Stroop experiments, so when it produced data for this prompt, it used patterns that were available from the training set to generate simulated data. Or is that possible? I don’t know enough about how these models work to answer the question."
  },
  {
    "objectID": "writing/Interim_overview.html#simulation-2-stroop-instructions",
    "href": "writing/Interim_overview.html#simulation-2-stroop-instructions",
    "title": "Interim Overview",
    "section": "Simulation 2: Stroop instructions",
    "text": "Simulation 2: Stroop instructions\nThis simulation includes some additional encouragement in the prompt to generate more realistic reaction times (not always ending in 0), and to make mistakes on some trials. Otherwise, it was similar to the first simulation. Again, it produces a Stroop effect with inter and intra-individual variability in reaction times.\n\nThis time the reaction times did not all end in 0, and collectively they even looked similar to human reaction time distributions (see simulation 2). The accuracy data was perfect for congruent trials, but mistakes were inserted on incongruent trials as instructed.\nThe take-home message was that changing the prompt did cause the model to produce reaction times and accuracy rates that conformed to the prompt instructions."
  },
  {
    "objectID": "writing/Interim_overview.html#simulations-3-to-6-proportion-congruent-and-refactoring-the-code-for-longer-prompts",
    "href": "writing/Interim_overview.html#simulations-3-to-6-proportion-congruent-and-refactoring-the-code-for-longer-prompts",
    "title": "Interim Overview",
    "section": "Simulations 3 to 6: Proportion congruent and refactoring the code for longer prompts",
    "text": "Simulations 3 to 6: Proportion congruent and refactoring the code for longer prompts\nThe first simulation showed that GPT generated both a typical Stroop effect and a congruency sequence effect, even though it wasn’t given information about how human performance depends on trial-to-trial aspects of the task.\nThe size of the Stroop effect is also known to depend on the relative proportion of congruent items in a list. The Stroop effect is typically larger for lists that contain a high proportion of congruent items compared to lists that contain a low proportion of congruent items.\nSimulation 3 was similar to the first simulation, with one key difference. It involved providing certain simulated subjects a set of trials containing a high proportion of congruent items, while others received a set of trials with a low proportion of congruent items. However, this simulation encountered several problems, as it frequently generated invalid JSON that couldn’t be analyzed. One of the contributing factors was the excessive length and token usage in the prompt, surpassing the model’s allowable limit.\nSimulations 4 and 5 were attempts to refactor the code to allow for longer prompts that returned results that could be analyzed. Simulation 5 worked quite well, and the approach used there was also employed in simulation 6.\nSimulation 6 gave some subjects a high proportion of congruent list items, and other subjects a low proportion of congruent list items. Interestingly, the model appeared to show the standard list-wide proportion congruent effect, even though the prompt mentioned nothing about this. The figure shows a larger simulated Stroop effect for the high proportion congruent conditions than the low proportion congruent conditions."
  },
  {
    "objectID": "writing/Interim_overview.html#simulation-7-and-8-stroop-task-switching",
    "href": "writing/Interim_overview.html#simulation-7-and-8-stroop-task-switching",
    "title": "Interim Overview",
    "section": "Simulation 7 and 8: Stroop Task-switching",
    "text": "Simulation 7 and 8: Stroop Task-switching\nI thought it was interesting that GPT produced a congruency sequence effect and a proportion congruent effect. I wondered how many other known effects it would produce in addition to the main Stroop effect, which is still very commonly observed in human data.\nSimulation 7 involved a task-switching procedure. In each trial, the model was randomly prompted to identify either the color or the word from a Stroop stimulus. Typically, human participants would exhibit quicker word naming responses than color naming responses, along with exhibiting smaller Stroop effects on word naming trials compared to color naming trials. However, the model did not demonstrate faster word naming responses compared to color naming responses, nor did it generate smaller Stroop effects on word naming trials compared to color naming trials.\nHumans typically show faster responses on task-repeat than task-switch trials. The model did not show this task switching effect either.\nThe figure shows the data from the model. The RTs for the identify word condition should have been much faster, and the difference between congruent and incongruent much smaller.\n\nSimulation 8 repeated the previous simulation but gave prompts that were more explicit about how the model should behave. The relevant additions are in bold.\n\nYou are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file. Your task is to simulate human performance in a word and color naming task. You will be given the task in the form a JSON object. The JSON object contains the word and color presented on each trial. Your task is to read the task instruction for each trial. If the instruction is to name the color, then identify the color as quickly and accurately as a human would. If the instruction is to name the word, then identify the word as quickly and accurately as a human would. Humans are much faster at naming words than colors. Humans show much larger Stroop effects for naming colors, and very small or nonexistent Stroop effects when naming words. When humans repeat the same task from trial to trial they are faster and more accurate compared to when they switch tasks from trial to trial. When you simulate data make sure it conforms to how humans would perform this task. The JSON object contains the symbol ? in locations where you will generate simulated responses. You will generate a simulated identification response, and a simulated reaction time for each trial. Put the simulated identification response and reaction time into a JSON array using this format…(see the code for details)\n\nHowever, in this case, the explicit instructions didn’t seem to change the model’s simulated results. It showed no difference between color and word-naming. And, it didn’t show a task-switching effect either."
  },
  {
    "objectID": "writing/Interim_overview.html#thats-it-for-now",
    "href": "writing/Interim_overview.html#thats-it-for-now",
    "title": "Interim Overview",
    "section": "That’s it for now",
    "text": "That’s it for now"
  },
  {
    "objectID": "modeling/S10_simon.html",
    "href": "modeling/S10_simon.html",
    "title": "Simulation 10: Simon Task",
    "section": "",
    "text": "Started. Finished."
  },
  {
    "objectID": "modeling/S10_simon.html#state",
    "href": "modeling/S10_simon.html#state",
    "title": "Simulation 10: Simon Task",
    "section": "",
    "text": "Started. Finished."
  },
  {
    "objectID": "modeling/S10_simon.html#recap",
    "href": "modeling/S10_simon.html#recap",
    "title": "Simulation 10: Simon Task",
    "section": "Recap",
    "text": "Recap\nThe previous simulations focused on the Stroop and Flanker tasks. This simulation uses a version of the Simon task.\nIn a Simon task, participants respond to stimulus using a right or left manual response. For example, a red circle could require the right response, and a green circle a left response. The stimuli are presented in one of two locations on a screen: to the left or right of center. In this case, the spatial location of the stimulus can interfere with the assigned response to identify the stimulus. For example, people are faster to press the right key to identify the red stimulus when it is presented in the right location compared to the left location on the screen."
  },
  {
    "objectID": "modeling/S10_simon.html#load-libraries",
    "href": "modeling/S10_simon.html#load-libraries",
    "title": "Simulation 10: Simon Task",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S10_simon.html#run-model",
    "href": "modeling/S10_simon.html#run-model",
    "title": "Simulation 10: Simon Task",
    "section": "Run model",
    "text": "Run model\nNotes: 20 simulated subjects. 20 Simon trials each. 50/50 congruent and incongruent trials.\nThe prompt contains only basic information to complete the task.\nUsed gpt-3.5-turbo-16k, with max tokens 10000.\nProblems: Still getting the occasional invalid JSON back, mostly due to the chatbot prefacing its response with a message before the JSON. This thread may be helpful https://community.openai.com/t/getting-response-data-as-a-fixed-consistent-json-response/28471/31?page=2.\n\n\nShow the code\n# Use letters H and F\n\nsimon_items &lt;- data.frame(stimulus = c(\"red\",\"red\",\"green\",\"green\"),\n                           instruction = \"Identify stimulus. Respond right for red. Respond left for green.\",\n                           location = c(\"left\",\"right\",\"left\",\"right\"),\n                           response = \"?\",\n                           reaction_time = \"?\")\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:20){\n  print(i)\n  \n  # construct trials data frame\n  simon_trials &lt;- simon_items[rep(1:nrow(simon_items),5),]\n \n  trials &lt;- simon_trials \n  trials &lt;- trials[sample(1:nrow(trials)),]\n  trials &lt;- trials %&gt;%\n    mutate(trial = 1:nrow(trials)) %&gt;%\n    relocate(instruction) %&gt;%\n    relocate(trial)\n  \n   # run the api call to openai\n  \n gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo-16k\",\n   max_tokens = 10000,\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file. Do not include any explanations, only provide a RFC8259 compliant JSON response.\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste('You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in JSON. Your task is to simulate human performance in a letter identification task. You will be given the task in the form a JSON object. The JSON object contains the task instruction and the stimulus on each trial. Your task is to follow the instruction and respond to the stimulus as quickly and accurately as a human participant would. The instructions are to identify the stimulus by responding right for red, and responding left for green. When you simulate data make sure it conforms to how humans would perform this task. The JSON object contains the symbol ? in locations where you will generate simulated responses. You will generate a simulated identification response, and a simulated reaction time for each trial. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"instruction\" = \"the task instruction, string\", \"stimulus\": \"the stimulus, string\", \"location\": \"the location of the stimulus, string\", \"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].', \"\\n\\n\", jsonlite::toJSON(trials), collapse = \"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  print(gpt_response$usage$total_tokens)\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n  print(test_JSON)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"instruction\",\"stimulus\",\"location\",\"response\",\"reaction_time\")) == 6) {\n      \n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_10.RData\")"
  },
  {
    "objectID": "modeling/S10_simon.html#analysis",
    "href": "modeling/S10_simon.html#analysis",
    "title": "Simulation 10: Simon Task",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_10.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 20 times.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 19 out of 20 valid simulated subjects.\n\nReaction time analysis\nThe model made too many mistakes to analyse RTs.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(reaction_time = as.numeric(reaction_time))\n\n# get mean RTs in each condition for each subject\nrt_data_subject_compatible &lt;- all_sim_data %&gt;%\n  mutate(compatible = case_when(stimulus == \"red\" && location == \"right\" ~ \"compatible\",\n                                stimulus == \"red\" && location == \"left\" ~ \"incompatible\",\n                                stimulus == \"green\" && location == \"right\" ~ \"incompatible\",\n                                stimulus == \"green\" && location == \"left\" ~ \"compatible\")\n         )%&gt;%\n  mutate(accuracy = case_when(stimulus == \"red\" && response == \"right\" ~ TRUE,\n                              stimulus == \"red\" && response != \"right\" ~ FALSE,\n                              stimulus == \"green\" && response == \"left\" ~ TRUE,\n                              stimulus == \"green\" && response != \"left\" ~ FALSE\n                              )\n         ) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(compatible,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n\n# Compute difference scores for each subject\nrt_data_subject_simon &lt;- rt_data_subject_compatible %&gt;%\n  pivot_wider(names_from = compatible,\n              values_from = mean_rt) %&gt;%\n  mutate(Simon_effect = incompatible-compatible)\n\n# make plots\n\nF1A &lt;- ggplot(rt_data_subject_compatible, aes(x = compatible,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  ggtitle(\"A\")\n\nF1B &lt;- ggplot(rt_data_subject_simon, aes(x = ' ',\n                                   y = Simon_effect))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Simon Effects\")+\n  xlab(\"Incompatible - Compatible\")+\n  ggtitle(\"B\")\n\nF1A + F1B\n\n\n\n\nA closer look at reaction times\nHere is a histogram of the individual simulated reaction times.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe prompt did not specify to produce values with different endings. As with previous simulations, the model prefers values ending in 0.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/S10_simon.html#accuracy-analysis",
    "href": "modeling/S10_simon.html#accuracy-analysis",
    "title": "Simulation 10: Simon Task",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(compatible = case_when(stimulus == \"red\" & location == \"right\" ~ \"compatible\",\n                                stimulus == \"red\" & location == \"left\" ~ \"incompatible\",\n                                stimulus == \"green\" & location == \"right\" ~ \"incompatible\",\n                                stimulus == \"green\" & location == \"left\" ~ \"compatible\")\n         )%&gt;%\n  mutate(accuracy = case_when(stimulus == \"red\" & response == \"right\" ~ TRUE,\n                              stimulus == \"red\" & response != \"right\" ~ FALSE,\n                              stimulus == \"green\" & response == \"left\" ~ TRUE,\n                              stimulus == \"green\" & response != \"left\" ~ FALSE\n                              )\n         )  %&gt;%\n  group_by(compatible,sim_subject) %&gt;%\n  summarize(proportion_correct = mean(accuracy), .groups = \"drop\")\n\nggplot(accuracy_data_subject, aes(x = compatible,\n                                  y = proportion_correct))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Proportion Correct\")+\n  xlab(\"Compatibility\")\n\n\n\n\n\nThere was a clear Simon effect in the accuracy data. There were several simulated subjects who had no correct trials in one of the two conditions, so reaction time data wasn’t analyzed further."
  },
  {
    "objectID": "modeling/S10_simon.html#discussion",
    "href": "modeling/S10_simon.html#discussion",
    "title": "Simulation 10: Simon Task",
    "section": "Discussion",
    "text": "Discussion\nThe model in some sense fell prey to the Simon effect, as it performed terribly on incompatible trials. On the one hand it had no problem issuing responses, but the data did not resemble typical ranges of reaction times in this task. Perhaps the GPT simulation would improve with variations on the prompt structure."
  },
  {
    "objectID": "modeling/todo.html#modelling-to-do",
    "href": "modeling/todo.html#modelling-to-do",
    "title": "Project Scratchpad",
    "section": "Modelling To do",
    "text": "Modelling To do\nNot an exhaustive list, something to get me started.\n\nSettle on one script that can be extended across the examples.\nRun multiple subjects, say batches of 20-30, which should be enough for the kinds of questions I want to ask\n\nAnswer the following basic questions\n\nDoes the model produce Stroop effects in RT and accuracy?\nDoes the model produce different answers for each run of simulated subjects?\nDoes the model produce RTs that look like human subject RTs?\nDoes the model produce additional Stroop phenomena without further prompting?\n\nCongruency sequence effect?\nProportion Congruent effect?\n\nCan the instruction prompt be used to control how the model simulates performance.\n\nsimulate 75% correct\n[] simulate 50% correct\nsimulate some long reaction times\nsimulate a reverse Stroop effect.\n[] simulate proportion congruent effects\n\n[] simulate some other tasks\nFlanker task\nSimon Task\n[] SRT (Nissen & Bullemer)\n[] Negative Priming\n[] Inhibition of Return\n[] SNARC effect"
  },
  {
    "objectID": "modeling/todo.html#writing-to-do",
    "href": "modeling/todo.html#writing-to-do",
    "title": "Project Scratchpad",
    "section": "Writing to do",
    "text": "Writing to do\n\ninterim overview\n[] consider in more detail what I’m trying to accomplish here and whether this project turns into something more formal than a shared repo on github\n[] Things that make me go hmmm.\n\nthe modeling work is not reproducible\nopenAI says the new default is that data sent through the API will not be used to train models, but this is an opt-in option\nI did not opt in, but if someone else did and re-ran this kind of code with feedback to alter the model resposnes, then the results from this kind of work would change\nUnclear what happens with newer models like GPT 4"
  },
  {
    "objectID": "modeling/S11_SNARC.html",
    "href": "modeling/S11_SNARC.html",
    "title": "Simulation 11: SNARC effect",
    "section": "",
    "text": "Started. Finished."
  },
  {
    "objectID": "modeling/S11_SNARC.html#state",
    "href": "modeling/S11_SNARC.html#state",
    "title": "Simulation 11: SNARC effect",
    "section": "",
    "text": "Started. Finished."
  },
  {
    "objectID": "modeling/S11_SNARC.html#recap",
    "href": "modeling/S11_SNARC.html#recap",
    "title": "Simulation 11: SNARC effect",
    "section": "Recap",
    "text": "Recap\nThis is a GPT simulation of the SNARC effect, which is commonly observed in participants who have a mental number line with small to large numbers going from left to right.\nA participant is presented with a digit from 1 to 9, and they judge whether the digit is odd or even with a right or left button press. People are faster to press the left button when the stimulus is a small number compared to a large number, and faster to press the right button when the stimulus is a large number compared to a small number."
  },
  {
    "objectID": "modeling/S11_SNARC.html#load-libraries",
    "href": "modeling/S11_SNARC.html#load-libraries",
    "title": "Simulation 11: SNARC effect",
    "section": "Load libraries",
    "text": "Load libraries\n\n\nShow the code\nlibrary(tidyverse)\nlibrary(openai)\nlibrary(patchwork)\nlibrary(xtable)"
  },
  {
    "objectID": "modeling/S11_SNARC.html#run-model",
    "href": "modeling/S11_SNARC.html#run-model",
    "title": "Simulation 11: SNARC effect",
    "section": "Run model",
    "text": "Run model\nNotes: 20 simulated subjects. 32 trials each. Stimuli were 1,2,3,4,6,7,8,9. Respond left for odd, right for even.\nThe prompt contains only basic information to complete the task.\nUsed gpt-3.5-turbo-16k, with max tokens 10000.\nProblems: Still getting the occasional invalid JSON back, mostly due to the chatbot prefacing its response with a message before the JSON. This thread may be helpful https://community.openai.com/t/getting-response-data-as-a-fixed-consistent-json-response/28471/31?page=2.\n\n\nShow the code\n# Use numbers 1 to 9.\n\nsnarc_items &lt;- data.frame(stimulus = c(1,2,3,4,6,7,8,9),\n                           instruction = \"Respond left for odd, right for even numbers\",\n                           response = \"?\",\n                           reaction_time = \"?\")\n\n#set up variables to store data\nall_sim_data &lt;- tibble()\ngpt_response_list &lt;- list()\n\n# request multiple subjects\n# submit a query to open ai using the following prompt\n# note: responses in JSON format are requested\n\nfor(i in 1:20){\n  print(i)\n  \n  # construct trials data frame\n  snarc_trials &lt;- snarc_items[rep(1:nrow(snarc_items),4),]\n \n  trials &lt;- snarc_trials \n  trials &lt;- trials[sample(1:nrow(trials)),]\n  trials &lt;- trials %&gt;%\n    mutate(trial = 1:nrow(trials)) %&gt;%\n    relocate(instruction) %&gt;%\n    relocate(trial)\n  \n   # run the api call to openai\n  \n gpt_response &lt;- create_chat_completion(\n   model = \"gpt-3.5-turbo-16k\",\n   max_tokens = 10000,\n   messages = list(\n       list(\n           \"role\" = \"system\",\n           \"content\" = \"You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in a JSON file. Do not include any explanations, only provide a RFC8259 compliant JSON response.\"),\n       list(\"role\" = \"assistant\",\n            \"content\" = \"OK, I am ready.\"),\n       list(\"role\" = \"user\",\n           \"content\" = paste('You are a simulated participant in a human cognition experiment. Complete the task as instructed and record your simulated responses in JSON. Your task is to simulate human performance in a number judgment task. You will be given the task in the form a JSON object. The JSON object contains the task instruction and the stimulus on each trial. Your task is to follow the instruction and respond to the stimulus as quickly and accurately as a human participant would. The instructions are to identify the stimulus by responding left for odd numbers and right for even numbers. When you simulate data make sure it conforms to how humans would perform this task. The JSON object contains the symbol ? in locations where you will generate simulated responses. You will generate a simulated identification response, and a simulated reaction time for each trial. Put the simulated identification response and reaction time into a JSON array using this format: [{\"trial\": \"trial number, integer\", \"instruction\" = \"the task instruction, string\", \"stimulus\": \"the stimulus, integer\", \"response\": \"the simulated identification response, string\",\"reaction_time\": \"the simulated reaction time, milliseconds an integer\"}].', \"\\n\\n\", jsonlite::toJSON(trials), collapse = \"\\n\")\n           \n       )\n   )\n)\n  \n  # save the output from openai\n  gpt_response_list[[i]] &lt;- gpt_response\n  print(gpt_response$usage$total_tokens)\n  \n  # validate the JSON  \n  test_JSON &lt;- jsonlite::validate(gpt_response$choices$message.content)\n  print(test_JSON)\n\n  # validation checks pass, write the simulated data to all_sim_data \n  if(test_JSON == TRUE){\n    sim_data &lt;- jsonlite::fromJSON(gpt_response$choices$message.content)\n    \n    if(sum(names(sim_data) == c(\"trial\",\"instruction\",\"stimulus\",\"response\",\"reaction_time\")) == 5) {\n      \n      sim_data &lt;- sim_data %&gt;%\n        mutate(sim_subject = i)\n  \n      all_sim_data &lt;- rbind(all_sim_data,sim_data)\n    }\n    \n  }\n}\n\n# model responses are in JSON format\nsave.image(\"data/simulation_11.RData\")"
  },
  {
    "objectID": "modeling/S11_SNARC.html#analysis",
    "href": "modeling/S11_SNARC.html#analysis",
    "title": "Simulation 11: SNARC effect",
    "section": "Analysis",
    "text": "Analysis\n\n\nShow the code\nload(file = \"data/simulation_11.RData\")\n\n\nThe LLM occasionally returns invalid JSON. The simulation ran 20 times.\n\n\nShow the code\ntotal_subjects &lt;- length(unique(all_sim_data$sim_subject))\n\n\nThere were 17 out of 20 valid simulated subjects.\n\nReaction time analysis\nThe model made too many mistakes to analyse RTs.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(reaction_time = as.numeric(reaction_time))\n\n# get mean RTs in each condition for each subject\nrt_data_subject_compatible &lt;- all_sim_data %&gt;%\n  mutate(odd_even = case_when(stimulus %% 2 == 0 ~ \"even\",\n                              stimulus %% 2 != 0 ~ \"odd\"),\n         correct_response = case_when(odd_even == \"odd\" ~ \"left\",\n                                      odd_even == \"even\" ~ \"right\")) %&gt;%\n  mutate(compatible = case_when(stimulus &lt; 5 & correct_response == \"left\" ~ \"compatible\",\n                                stimulus &lt; 5 & correct_response == \"right\" ~ \"incompatible\",\n                                stimulus &gt; 5 & correct_response == \"left\" ~ \"incompatible\",\n                                stimulus &gt; 5 & correct_response == \"right\" ~ \"compatible\")\n         ) %&gt;%\n  mutate(accuracy = case_when(correct_response == response ~ TRUE,\n                              correct_response != response ~ FALSE\n                              )\n         ) %&gt;%\n  filter(accuracy == TRUE) %&gt;%\n  group_by(compatible,sim_subject) %&gt;%\n  summarize(mean_rt = mean(reaction_time), .groups = \"drop\")\n\n\n# Compute difference scores for each subject\nrt_data_subject_SNARC &lt;- rt_data_subject_compatible %&gt;%\n  pivot_wider(names_from = compatible,\n              values_from = mean_rt) %&gt;%\n  mutate(SNARC_effect = incompatible-compatible)\n\n# make plots\n\nF1A &lt;- ggplot(rt_data_subject_compatible, aes(x = compatible,\n                                       y = mean_rt))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Mean Simulated Reaction Time\") +\n  ggtitle(\"A\")\n\nF1B &lt;- ggplot(rt_data_subject_SNARC, aes(x = ' ',\n                                   y = SNARC_effect))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated SNARC Effects\")+\n  xlab(\"Incompatible - Compatible\")+\n  ggtitle(\"B\")\n\nF1A + F1B\n\n\n\n\n\n13 out of 17 simulated subjects showed a positive SNARC effect.\n\n\nA closer look at reaction times\nHere is a histogram of the individual simulated reaction times.\n\n\nShow the code\nggplot(all_sim_data, aes(x=reaction_time))+\n  geom_histogram(binwidth=50, color=\"white\")+\n  theme_classic()+\n  xlab(\"Simulated Reaction Times\")\n\n\n\n\n\nThe prompt did not specify to produce values with different endings. As with previous simulations, the model prefers values ending in 0.\n\n\nShow the code\nall_sim_data &lt;- all_sim_data %&gt;%\n  mutate(ending_digit = stringr::str_extract(all_sim_data$reaction_time, \"\\\\d$\")) %&gt;%\n  mutate(ending_digit = as.numeric(ending_digit))\n\nggplot(all_sim_data, aes(x=ending_digit))+\n  geom_histogram(binwidth=1, color=\"white\")+\n  scale_x_continuous(breaks=seq(0,9,1))+\n  theme_classic(base_size = 10)+\n  xlab(\"Simulated RT Ones Digit\")"
  },
  {
    "objectID": "modeling/S11_SNARC.html#accuracy-analysis",
    "href": "modeling/S11_SNARC.html#accuracy-analysis",
    "title": "Simulation 11: SNARC effect",
    "section": "Accuracy Analysis",
    "text": "Accuracy Analysis\n\n\nShow the code\n# report accuracy data\naccuracy_data_subject &lt;- all_sim_data %&gt;%\n  mutate(odd_even = case_when(stimulus %% 2 == 0 ~ \"even\",\n                              stimulus %% 2 != 0 ~ \"odd\"),\n         correct_response = case_when(odd_even == \"odd\" ~ \"left\",\n                                      odd_even == \"even\" ~ \"right\")) %&gt;%\n  mutate(compatible = case_when(stimulus &lt; 5 & correct_response == \"left\" ~ \"compatible\",\n                                stimulus &lt; 5 & correct_response == \"right\" ~ \"incompatible\",\n                                stimulus &gt; 5 & correct_response == \"left\" ~ \"incompatible\",\n                                stimulus &gt; 5 & correct_response == \"right\" ~ \"compatible\")\n         ) %&gt;%\n  mutate(accuracy = case_when(correct_response == response ~ TRUE,\n                              correct_response != response ~ FALSE\n          ))  %&gt;%\n  group_by(compatible,sim_subject) %&gt;%\n  summarize(proportion_correct = mean(accuracy), .groups = \"drop\")\n\nggplot(accuracy_data_subject, aes(x = compatible,\n                                  y = proportion_correct))+\n  geom_violin()+\n  stat_summary(fun = \"mean\",\n               geom = \"crossbar\",\n               color = \"red\")+\n  geom_point()+\n  theme_classic(base_size=15)+\n  ylab(\"Simulated Proportion Correct\")+\n  xlab(\"Compatibility\")\n\n\n\n\n\nThe model was always made correct responses."
  },
  {
    "objectID": "modeling/S11_SNARC.html#discussion",
    "href": "modeling/S11_SNARC.html#discussion",
    "title": "Simulation 11: SNARC effect",
    "section": "Discussion",
    "text": "Discussion\nIt appears that the model produced a typical SNARC effect with minimal prompting. I did not counterbalance whether the odd or even response was left or right."
  }
]